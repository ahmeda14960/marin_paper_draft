# OLMo 2 ("2 OLMo 2 Furious") — Reading Notes and Citation Guide

This file summarizes the OLMo 2 paper in `other_papers/olmo2/` with emphasis on (1) how it frames related work, and (2) what each citation is doing in-context.

## High-Level Takeaways
- Fully-open release: weights + full training data + training code/recipes + logs + many intermediate checkpoints.
- Base model family at 7B/13B/32B trained up to ~6T tokens, positioned on a performance/compute Pareto frontier vs strong open-weight baselines.
- Primary engineering/science targets: pretraining stability, mid-training (two-stage) curricula, post-training (SFT/DPO/RLVR) on permissive data, and infrastructure/operations.
- Architecture changes are motivated explicitly by stability (norm reordering, QK-norm, z-loss, RoPE theta change, embedding WD choices).
- Introduces a specialized late-stage data mixture (Dolmino) and “micro-annealing” as a low-cost proxy to screen mid-training mixtures.
- Uses standardized evaluation conventions (OLMES-style) and reports both base and instruct metrics.

## Related Work Map (Roles → Representative Citations)
These are automatically selected by citation frequency within each role category (so they skew toward what the paper “leans on” most).

### Fully open model / precedent
- `Groeneveld2024OLMoAT` — *Olmo: Accelerating the science of language models* (2024) — cited 9x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024* (2024) — cited 7x
- `olmo_blog` — *OLMo-1.7 7B: A 24-point improvement on MMLU, 4 2024* (2024) — cited 5x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 4x
- `biderman2023pythia` — *Pythia: A suite for analyzing large language models across training and scaling* (2023) — cited 1x
- `liu2023llm360` — *Llm360: Towards fully transparent open-source llms* (2023c) — cited 1x
- `zhang2024mapneo` — *Map-neo: Highly capable and transparent bilingual large language model series* (2024a) — cited 1x
- `allal2024SmolLM` — *Smollm - blazingly fast and remarkably powerful, 07 2024a* (2024a) — cited 1x

### Open-weight model / baseline
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 6x
- `abdin2024phi` — *Phi-3 technical report: A highly capable language model locally on your phone* (2024a) — cited 5x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 5x
- `dbrx_blog` — *Introducing DBRX: A New State-of-the-Art Open LLM, 3 2024* (2024) — cited 3x
- `young2024yi` — *Yi: Open foundation models by 01. ai* (2024) — cited 3x
- `gemma2` — *Gemma 2: Improving open language models at a practical size* (2024b) — cited 3x
- `together2023redpajama` — *RedPajama: An open source recipe to reproduce LLaMA training dataset, 2023* (2023) — cited 3x
- `yang2025qwen3technicalreport` — *Qwen3 technical report* (2025) — cited 2x

### Data / preprocessing / filtering
- `cobbe2021trainingverifierssolvemath` — *Training verifiers to solve math word problems, 2021* (2021) — cited 8x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024* (2024) — cited 7x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 4x
- `paster2023openwebmath` — *Openwebmath: An open dataset of high-quality mathematical web text, 2023* (2023) — cited 4x
- `together2023redpajama` — *RedPajama: An open source recipe to reproduce LLaMA training dataset, 2023* (2023) — cited 3x
- `peS2o` — *peS2o (Pretraining Efficiently on S2ORC) Dataset, 2023* (2023) — cited 3x
- `azerbayev2023llemma` — *Llemma: An open language model for mathematics, 2023* (2023) — cited 3x
- `li2023starcoder` — *Starcoder: may the source be with you!, 2023b* (2023b) — cited 2x

### Training recipe / curriculum
- `cobbe2021trainingverifierssolvemath` — *Training verifiers to solve math word problems, 2021* (2021) — cited 8x
- `abdin2024phi` — *Phi-3 technical report: A highly capable language model locally on your phone* (2024a) — cited 5x
- `blakeney2024doesdatasparkjoy` — *Does your data spark joy? performance gains from domain upsampling at the end of training, 2024* (2024) — cited 3x
- `mitch` — *Small-scale proxies for large-scale transformer training instabilities, 2023* (2023) — cited 3x
- `azerbayev2023llemma` — *Llemma: An open language model for mathematics, 2023* (2023) — cited 3x
- `yang2024spectral` — *A spectral condition for feature learning, 2024b* (2024b) — cited 3x
- `ibrahim2024simplescalablestrategiescontinually` — *Simple and scalable strategies to continually pre-train large language models, 2024* (2024) — cited 2x
- `gururangan2020dontStopPretraining` — *Don’t stop pretraining: Adapt language models to domains and tasks* (2020) — cited 2x

### Architecture / optimization component
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 6x
- `chameleon` — *Chameleon: Mixed-modal early-fusion foundation models* (2024) — cited 3x
- `mitch` — *Small-scale proxies for large-scale transformer training instabilities, 2023* (2023) — cited 3x
- `vaswani2017attention` — *Attention is all you need* (2017) — cited 2x
- `swin2` — *Swin transformer v2: Scaling up capacity and resolution* (2021) — cited 2x
- `Zhang2019ImprovingDT` — *Improving deep transformer with depth-scaled initialization and merged attention* (2019) — cited 2x
- `Shazeer2020GLUVI` — *Glu variants improve transformer* (2020) — cited 1x
- `Su2021RoFormerET` — *Roformer: Enhanced transformer with rotary position embedding* (2021) — cited 1x

### Training stability / optimization
- `Groeneveld2024OLMoAT` — *Olmo: Accelerating the science of language models* (2024) — cited 9x
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 6x
- `olmo_blog` — *OLMo-1.7 7B: A 24-point improvement on MMLU, 4 2024* (2024) — cited 5x
- `dbrx_blog` — *Introducing DBRX: A New State-of-the-Art Open LLM, 3 2024* (2024) — cited 3x
- `palm` — *Palm: Scaling language modeling with pathways* (2022) — cited 3x
- `chameleon` — *Chameleon: Mixed-modal early-fusion foundation models* (2024) — cited 3x
- `mitch` — *Small-scale proxies for large-scale transformer training instabilities, 2023* (2023) — cited 3x
- `yang2024spectral` — *A spectral condition for feature learning, 2024b* (2024b) — cited 3x

### Evaluation benchmark / methodology
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 19x
- `Groeneveld2024OLMoAT` — *Olmo: Accelerating the science of language models* (2024) — cited 9x
- `olmes` — *Olmes: A standard for language model evaluations* (2024) — cited 9x
- `cobbe2021trainingverifierssolvemath` — *Training verifiers to solve math word problems, 2021* (2021) — cited 8x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024* (2024) — cited 7x
- `olmo_blog` — *OLMo-1.7 7B: A 24-point improvement on MMLU, 4 2024* (2024) — cited 5x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 5x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 4x

### Post-training / alignment
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 19x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 5x
- `chan2024scaling` — *Scaling synthetic data creation with 1,000,000,000 personas* (2024) — cited 4x
- `allal2024SmolLM2` — *Smollm2 - with great data, comes great performance, 11 2024b* (2024b) — cited 2x
- `jiang2023mistral` — *Mistral 7b* (2023) — cited 2x
- `mistralnemo` — *Mistral introduces NeMO, 2024* (2024) — cited 2x
- `akter2024mindmathinformedsynthetic` — *Mind: Math informed synthetic dialogues for pretraining llms, 2024* (2024) — cited 2x
- `ivison2023camels` — *Camels in a changing climate: Enhancing lm adaptation with tulu 2* (2023) — cited 2x

### Scaling laws / compute framing
- `olmes` — *Olmes: A standard for language model evaluations* (2024) — cited 9x
- `chan2024scaling` — *Scaling synthetic data creation with 1,000,000,000 personas* (2024) — cited 4x
- `palm` — *Palm: Scaling language modeling with pathways* (2022) — cited 3x
- `chameleon` — *Chameleon: Mixed-modal early-fusion foundation models* (2024) — cited 3x
- `yang2024spectral` — *A spectral condition for feature learning, 2024b* (2024b) — cited 3x
- `kaplan2020scaling` — *Scaling laws for neural language models* (2020) — cited 2x
- `swin2` — *Swin transformer v2: Scaling up capacity and resolution* (2021) — cited 2x
- `tao2024scaling` — *Scaling laws with vocabulary: Larger models deserve larger vocabularies* (2024) — cited 2x

### Infrastructure / systems
- `swin2` — *Swin transformer v2: Scaling up capacity and resolution* (2021) — cited 2x
- `Zhang2019ImprovingDT` — *Improving deep transformer with depth-scaled initialization and merged attention* (2019) — cited 2x
- `openlm` — *open\_lm: a minimal but performative language modeling (lm) repository, 2023* (2023) — cited 1x
- `beaker2022` — *Introducing Ai2’s beaker* (2022) — cited 1x
- `PyTorch2` — *Pytorch 2: Faster machine learning through dynamic python bytecode transformation and graph compilation* (2024) — cited 1x
- `pytorch2024cuda` — *CUDA semantics* (2024) — cited 1x
- `wriestimatingwater` — *Guidance for calculating water use embedded in purchased electricity, 2020* (2020) — cited 1x

## Most-Frequent Citations (Global)
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 19x
- `Groeneveld2024OLMoAT` — *Olmo: Accelerating the science of language models* (2024) — cited 9x
- `olmes` — *Olmes: A standard for language model evaluations* (2024) — cited 9x
- `cobbe2021trainingverifierssolvemath` — *Training verifiers to solve math word problems, 2021* (2021) — cited 8x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024* (2024) — cited 7x
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 6x
- `abdin2024phi` — *Phi-3 technical report: A highly capable language model locally on your phone* (2024a) — cited 5x
- `olmo_blog` — *OLMo-1.7 7B: A 24-point improvement on MMLU, 4 2024* (2024) — cited 5x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 5x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 4x
- `paster2023openwebmath` — *Openwebmath: An open dataset of high-quality mathematical web text, 2023* (2023) — cited 4x
- `chan2024scaling` — *Scaling synthetic data creation with 1,000,000,000 personas* (2024) — cited 4x
- `dbrx_blog` — *Introducing DBRX: A New State-of-the-Art Open LLM, 3 2024* (2024) — cited 3x
- `young2024yi` — *Yi: Open foundation models by 01. ai* (2024) — cited 3x
- `gemma2` — *Gemma 2: Improving open language models at a practical size* (2024b) — cited 3x
- `blakeney2024doesdatasparkjoy` — *Does your data spark joy? performance gains from domain upsampling at the end of training, 2024* (2024) — cited 3x
- `palm` — *Palm: Scaling language modeling with pathways* (2022) — cited 3x
- `chameleon` — *Chameleon: Mixed-modal early-fusion foundation models* (2024) — cited 3x
- `mitch` — *Small-scale proxies for large-scale transformer training instabilities, 2023* (2023) — cited 3x
- `together2023redpajama` — *RedPajama: An open source recipe to reproduce LLaMA training dataset, 2023* (2023) — cited 3x

## Annotated Reference Index (All Cited References)
Each entry lists the BibTeX key, reference title, a coarse “used for” rationale, coarse roles, and where it appears in the TeX sources.

- `abdin2024phi` — *Phi-3 technical report: A highly capable language model locally on your phone* (2024a, cited 5x). Used for: external model baseline and/or source of public recipes; evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Open-weight model / baseline, Training recipe / curriculum. Sections: Additional Hyperparameters; Deep Dive: \diveAnnealing; Introduction; \olmotoo Family > Base Model Training Recipe > Stage 2: Mid-training Files: appendix.tex, neurips_2023.tex
- `Abdin2024Phi4TR` — *Phi-4 technical report* (2024b, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `ainslie-etal-2023-gqa` — *GQA: Training generalized multi-query transformer models from multi-head checkpoints* (2023, cited 1x). Used for: origin/reference for an architecture or optimization component. Role(s): Architecture / optimization component. Sections: \olmotoo Family > Base Model Training Recipe > Stage 1: Pretraining Files: neurips_2023.tex
- `akter2024mindmathinformedsynthetic` — *Mind: Math informed synthetic dialogues for pretraining llms, 2024* (2024, cited 2x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > DolminoSynthMath; Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > TinyGSM-MIND Files: neurips_2023.tex
- `allal2024SmolLM` — *Smollm - blazingly fast and remarkably powerful, 07 2024a* (2024a, cited 1x). Used for: precedent for releasing weights + data + code (fully open). Role(s): Fully open model / precedent. Sections: Introduction Files: neurips_2023.tex
- `allal2024SmolLM2` — *Smollm2 - with great data, comes great performance, 11 2024b* (2024b, cited 2x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Additional Hyperparameters; Introduction Files: appendix.tex, neurips_2023.tex
- `Antoniades2024GeneralizationVM` — *Generalization v.s. memorization: Tracing language models' capabilities back to pretraining data* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `azerbayev2023llemma` — *Llemma: An open language model for mathematics, 2023* (2023, cited 3x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Training recipe / curriculum, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Academic, encyclopedic and other reference content; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `Ba2016LayerNorm` — *Layer normalization* (2016, cited 1x). Used for: origin/reference for an architecture or optimization component. Role(s): Architecture / optimization component. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `beaker2022` — *Introducing Ai2’s beaker* (2022, cited 1x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; benchmark definition or evaluation methodology/harness; systems/infra/training-stack reference. Role(s): Training recipe / curriculum, Evaluation benchmark / methodology, Infrastructure / systems. Sections: Deep Dive: \diveInfra > Beaker Files: neurips_2023.tex
- `bhagia2024establishingtaskscalinglaws` — *Establishing task scaling laws via compute-efficient model ladders, 2024* (2024, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology/harness. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology. Sections: Introduction Files: neurips_2023.tex
- `biderman2023pythia` — *Pythia: A suite for analyzing large language models across training and scaling* (2023, cited 1x). Used for: precedent for releasing weights + data + code (fully open); compute/performance scaling context (tokens, FLOPs, Pareto). Role(s): Fully open model / precedent, Scaling laws / compute framing. Sections: Introduction Files: neurips_2023.tex
- `biderman2024lessons` — *Lessons from the trenches on reproducible evaluation of language models* (2024, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: \olmotoo Evaluation Framework > Base Model Eval > Multiple-choice tasks Files: appendix.tex
- `black2022gpt` — *GPT-NeoX-20B: An open-source autoregressive language model* (2022, cited 1x). Used for: tokenizer/vocabulary design context. Role(s): Tokenizer / vocabulary. Sections: \olmotoo Family > Tokenizer Files: neurips_2023.tex
- `blakeney2024doesdatasparkjoy` — *Does your data spark joy? performance gains from domain upsampling at the end of training, 2024* (2024, cited 3x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing; Introduction; \olmotoo Family > Base Model Training Recipe Files: neurips_2023.tex
- `chameleon` — *Chameleon: Mixed-modal early-fusion foundation models* (2024, cited 3x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Scaling laws / compute framing, Architecture / optimization component, Training stability / optimization. Sections: Deep Dive: \diveStability > Architecture Improvements > Reordered norm and QK-norm; Deep Dive: \diveStability > Architecture Improvements > Z-Loss; \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `chan2024scaling` — *Scaling synthetic data creation with 1,000,000,000 personas* (2024, cited 4x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Post-training / alignment. Sections: Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > TuluMath; Deep Dive: \divePost > Supervised Finetuning (SFT) Files: figures/persona_prompts_math.tex, neurips_2023.tex
- `chang2024large` — *How do large language models acquire factual knowledge during pretraining?* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `chen2021codex` — *Evaluating large language models trained on code* (2021, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `clark-etal-2019-boolq` — *BoolQ: Exploring the surprising difficulty of natural yes/no questions* (2019, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval Files: appendix.tex
- `clark2018think` — *Think you have solved question answering? Try ARC, the AI2 reasoning challenge* (2018, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval Files: appendix.tex
- `cobbe2021trainingverifierssolvemath` — *Training verifiers to solve math word problems, 2021* (2021, cited 8x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Training recipe / curriculum, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Math; Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > GSM8K-Train; \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks; \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks; \olmotoo Family > Evaluation and Results > Base Model Evaluation: Files: appendix.tex, neurips_2023.tex, tables/microanneal.tex, tables/midtrain_results.tex
- `cohere2024commandR` — *Command R: Retrieval-Augmented Generation at Production Scale* (2024a, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `cohere2024commandR7B` — *Introducing Command R7B: Fast and efficient generative AI* (2024b, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `cohere2024commandRplus` — *Introducing Command R+: A Scalable LLM Built for Business* (2024c, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `cottier2024open` — *How far behind are open models?, Nov. 2024* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `cowsik2024geometric` — *Geometric dynamics of signal propagation predict trainability of transformers, 2024* (2024, cited 1x). Used for: origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Architecture / optimization component, Training stability / optimization. Sections: Deep Dive: \diveStability > Model Initialization > Gradient and activation growth Files: neurips_2023.tex
- `cui2023ultrafeedback` — *Ultrafeedback: Boosting language models with high-quality feedback* (2023, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Scaling laws / compute framing, Post-training / alignment. Sections: Deep Dive: \divePost > Preference Finetuning (PreFT) with DPO Files: neurips_2023.tex
- `dao2023flashattention2` — *FlashAttention-2: Faster attention with better parallelism and work partitioning* (2024, cited 1x). Used for: origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Architecture / optimization component, Training stability / optimization. Sections: Deep Dive: \diveStability > Architecture Improvements > Z-Loss Files: neurips_2023.tex
- `dbrx_blog` — *Introducing DBRX: A New State-of-the-Art Open LLM, 3 2024* (2024, cited 3x). Used for: external model baseline and/or source of public recipes; instability/loss-spike diagnosis and stabilization techniques. Role(s): Open-weight model / baseline, Training stability / optimization. Sections: Introduction; \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024* (2024, cited 7x). Used for: precedent for releasing weights + data + code (fully open); dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > Final Midtraining mix and Checkpoint Soups > Mid-training model merging or ``soups''; Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > High quality web; Introduction; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `Dehghani2023ScalingVT` — *Scaling vision transformers to 22 billion parameters* (2023b, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); origin/reference for an architecture or optimization component. Role(s): Scaling laws / compute framing, Architecture / optimization component. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `dodge2022measuringcarbonintensityai` — *Measuring the carbon intensity of ai in cloud instances, 2022* (2022, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `dua-etal-2019-drop` — *DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs* (2019, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Generative tasks Files: appendix.tex
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024, cited 6x). Used for: external model baseline and/or source of public recipes; tokenizer/vocabulary design context; origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Open-weight model / baseline, Tokenizer / vocabulary, Architecture / optimization component, Training stability / optimization. Sections: Deep Dive: \diveAnnealing > Learning rate annealing; Introduction; \olmotoo Family > Model Architecture Files: neurips_2023.tex, tables/environmental_impact.tex
- `dubois2024length` — *Length-controlled alpacaeval: A simple way to debias automatic evaluators* (2024, cited 1x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `eval-harness` — *A framework for few-shot language model evaluation* (2023, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: \olmotoo Evaluation Framework > Base Model Eval > Multiple-choice tasks Files: appendix.tex
- `evalplus` — *Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation* (2023b, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `falcon2` — *Meet falcon 2: TII releases new AI model series, outperforming meta’s new llama 3* (2024a, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `falcon3` — *Falcon 3: Making advanced AI accessible and available to everyone, everywhere* (2024b, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `falcon40b` — *Falcon-40B: an open large language model with state-of-the-art performance* (2023, cited 1x). Used for: external model baseline and/or source of public recipes; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Open-weight model / baseline, Post-training / alignment. Sections: Additional Hyperparameters Files: appendix.tex
- `fan2019eli5` — *Eli5: Long form question answering* (2019, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > High quality web Files: neurips_2023.tex
- `feng2024maximize` — *Maximize your data's potential: Enhancing llm accuracy with two-phase pretraining* (2024, cited 1x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing Files: neurips_2023.tex
- `gemma` — *Gemma: Open models based on gemini research and technology* (2024a, cited 1x). Used for: external model baseline and/or source of public recipes; benchmark definition or evaluation methodology/harness. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology. Sections: Introduction Files: neurips_2023.tex
- `gemma2` — *Gemma 2: Improving open language models at a practical size* (2024b, cited 3x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Additional Hyperparameters; Introduction Files: appendix.tex, neurips_2023.tex
- `gemmateam2025gemma3technicalreport` — *Gemma 3 technical report, 2025* (2025, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `gpt35` — *GPT-3.5 turbo, 2023a* (2023a, cited 1x). Used for: external model baseline and/or source of public recipes; tokenizer/vocabulary design context. Role(s): Open-weight model / baseline, Tokenizer / vocabulary. Sections: \olmotoo Family > Tokenizer Files: neurips_2023.tex
- `gpt4` — *GPT-4 technical report* (2023b, cited 1x). Used for: external model baseline and/or source of public recipes; tokenizer/vocabulary design context. Role(s): Open-weight model / baseline, Tokenizer / vocabulary. Sections: \olmotoo Family > Tokenizer Files: neurips_2023.tex
- `Groeneveld2024OLMoAT` — *Olmo: Accelerating the science of language models* (2024, cited 9x). Used for: precedent for releasing weights + data + code (fully open); instability/loss-spike diagnosis and stabilization techniques; benchmark definition or evaluation methodology/harness. Role(s): Fully open model / precedent, Training stability / optimization, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing; Deep Dive: \diveInfra > Environmental Impact; Introduction; \olmotoo Family; \olmotoo Family > Model Architecture Files: neurips_2023.tex, tables/environmental_impact.tex
- `grok_blog` — *Announcing Grok, 11 2023* (2023, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `gururangan2020dontStopPretraining` — *Don’t stop pretraining: Adapt language models to domains and tasks* (2020, cited 2x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing; \olmotoo Family > Base Model Training Recipe > Stage 2: Mid-training Files: neurips_2023.tex
- `hendrycksmath2021` — *Measuring mathematical problem solving with the math dataset* (2021b, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `hendryckstest2021` — *Measuring massive multitask language understanding* (2021a, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval Files: appendix.tex, tables/midtrain_results.tex
- `hurst2024gpt` — *Gpt-4o system card* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Additional Hyperparameters Files: appendix.tex
- `husain2019CodeSearchNet` — *CodeSearchNet challenge: Evaluating the state of semantic code search* (2019, cited 2x). Used for: dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Code; Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > ProofPile OWM-Filtered Files: neurips_2023.tex
- `ibrahim2024simplescalablestrategiescontinually` — *Simple and scalable strategies to continually pre-train large language models, 2024* (2024, cited 2x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing; \olmotoo Family > Base Model Training Recipe Files: neurips_2023.tex
- `ivison2023camels` — *Camels in a changing climate: Enhancing lm adaptation with tulu 2* (2023, cited 2x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Additional Hyperparameters Files: appendix.tex
- `jiang2023mistral` — *Mistral 7b* (2023, cited 2x). Used for: external model baseline and/or source of public recipes; compute/performance scaling context (tokens, FLOPs, Pareto); post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Open-weight model / baseline, Scaling laws / compute framing, Post-training / alignment. Sections: Additional Hyperparameters; \olmotoo Family > Evaluation and Results Files: appendix.tex, neurips_2023.tex
- `Jin2024DemystifyingLM` — *Demystifying language model forgetting with low-rank example associations* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `joshi-etal-2017-triviaqa` — *TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension* (2017, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks Files: appendix.tex
- `kaplan2020scaling` — *Scaling laws for neural language models* (2020, cited 2x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto). Role(s): Scaling laws / compute framing. Sections: \olmotoo Family > Evaluation and Results Files: neurips_2023.tex
- `karpathy2024spikes` — *Cool! For the spike I'd try e.g. `-sl 7 -sg 7` to keep instability in check earlier in the training. (will skip update if loss/gradnorm > 7 sigma outlier is detected)* (2024, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); instability/loss-spike diagnosis and stabilization techniques. Role(s): Scaling laws / compute framing, Training stability / optimization. Sections: Deep Dive: \diveStability > Model Initialization > Spike score Files: neurips_2023.tex
- `kocetkov2022stack3tbpermissively` — *The stack: 3 tb of permissively licensed source code, 2022* (2022, cited 2x). Used for: tokenizer/vocabulary design context; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Tokenizer / vocabulary, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `kwiatkowski-etal-2019-natural` — *Natural questions: A benchmark for question answering research* (2019, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Generative tasks Files: appendix.tex
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024, cited 19x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: Additional Instruct Details > Additional Hyperparameters; Deep Dive: \divePost; Deep Dive: \divePost > Evaluation of \olmotooinstruct; Deep Dive: \divePost > Hyperparameter selection; Deep Dive: \divePost > Reinforcement Learning with Verifiable Rewards (RLVR); Introduction; +2 more Files: appendix.tex, neurips_2023.tex, tables/eval-post.tex, tables/instruct-unseen.tex
- `land2024fishing` — *Fishing for magikarp: Automatically detecting under-trained tokens in large language models* (2024, cited 1x). Used for: tokenizer/vocabulary design context. Role(s): Tokenizer / vocabulary. Sections: Introduction Files: neurips_2023.tex
- `li2023makingaithirstyuncovering` — *Making ai less "thirsty": Uncovering and addressing the secret water footprint of ai models, 2023a* (2023a, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `li2023starcoder` — *Starcoder: may the source be with you!, 2023b* (2023b, cited 2x). Used for: tokenizer/vocabulary design context; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Tokenizer / vocabulary, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `lin2021truthfulqa` — *Truthfulqa: Measuring how models mimic human falsehoods* (2021, cited 1x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `liu2023llm360` — *Llm360: Towards fully transparent open-source llms* (2023c, cited 1x). Used for: precedent for releasing weights + data + code (fully open). Role(s): Fully open model / precedent. Sections: Introduction Files: neurips_2023.tex
- `liu2023tinygsmachieving80gsm8k` — *Tinygsm: achieving >80% on gsm8k with small language models, 2023a* (2023a, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > TinyGSM-MIND Files: neurips_2023.tex
- `longpre2023flan` — *The flan collection: Designing data and methods for effective instruction tuning* (2023, cited 1x). Used for: dataset or data-quality/filtering/dedup method; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Data / preprocessing / filtering, Post-training / alignment. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Instruction data and Q\&A pairs Files: neurips_2023.tex
- `luccioni2022estimatingcarbonfootprintbloom` — *Estimating the carbon footprint of bloom, a 176b parameter language model, 2022* (2022, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `mallen2023llm_memorization` — *When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories* (2022, cited 1x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `matena2022mergingmodelsfisherweightedaveraging` — *Merging models with fisher-weighted averaging* (2022, cited 1x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: \olmotoo Family > Base Model Training Recipe > Model Merging or ``Souping'' Files: neurips_2023.tex
- `mccandlish2018empirical` — *An empirical model of large-batch training* (2018, cited 1x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing > Learning rate annealing Files: neurips_2023.tex
- `merrick2024arctic` — *Arctic-embed: Scalable, efficient, and accurate text embedding models* (2024, cited 1x). Used for: dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > High quality web Files: neurips_2023.tex
- `mistral2024large2` — *Mistral Large 2: Large Enough* (2024a, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `mistral2024ministral` — *Un Ministral, des Ministraux: Introducing the world’s best edge models* (2024b, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `mistralnemo` — *Mistral introduces NeMO, 2024* (2024, cited 2x). Used for: external model baseline and/or source of public recipes; compute/performance scaling context (tokens, FLOPs, Pareto); post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Open-weight model / baseline, Scaling laws / compute framing, Post-training / alignment. Sections: Additional Hyperparameters; \olmotoo Family > Evaluation and Results Files: appendix.tex, neurips_2023.tex
- `mitch` — *Small-scale proxies for large-scale transformer training instabilities, 2023* (2023, cited 3x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Training recipe / curriculum, Architecture / optimization component, Training stability / optimization. Sections: Deep Dive: \diveAnnealing > Learning rate annealing; Deep Dive: \diveStability > Architecture Improvements > Z-Loss; \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `modelsoups` — *Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time, 2022* (2022, cited 2x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; compute/performance scaling context (tokens, FLOPs, Pareto). Role(s): Training recipe / curriculum, Scaling laws / compute framing. Sections: Deep Dive: \diveAnnealing > Final Midtraining mix and Checkpoint Soups > Mid-training model merging or ``soups''; \olmotoo Family > Base Model Training Recipe > Model Merging or ``Souping'' Files: neurips_2023.tex
- `mosaic-jeopardy` — *Llm foundry - jeopardy dataset* (2024, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval > Generative tasks Files: appendix.tex
- `MosaicML2023Introducing` — *Introducing mpt-30b: Raising the bar for open-source foundation models, 2023* (2023, cited 2x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Additional Hyperparameters Files: appendix.tex
- `muennighoff2024olmoeopenmixtureofexpertslanguage` — *Olmoe: Open mixture-of-experts language models, 2024* (2024, cited 1x). Used for: dataset or data-quality/filtering/dedup method. Role(s): Data / preprocessing / filtering. Sections: \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex
- `NuExtract15` — *Nuextract-1.5* (2024, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Additional Hyperparameters Files: appendix.tex
- `olmes` — *Olmes: A standard for language model evaluations* (2024, cited 9x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); tokenizer/vocabulary design context; benchmark definition or evaluation methodology/harness. Role(s): Scaling laws / compute framing, Tokenizer / vocabulary, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > Learning rate annealing; Introduction; \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Generative tasks; \olmotoo Evaluation Framework > Base Model Eval > Multiple-choice tasks; \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks; +2 more Files: appendix.tex, neurips_2023.tex
- `olmo-co2` — *Holistically evaluating the environmental impact of creating language models* (2025, cited 1x). Used for: precedent for releasing weights + data + code (fully open). Role(s): Fully open model / precedent. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `olmo_blog` — *OLMo-1.7 7B: A 24-point improvement on MMLU, 4 2024* (2024, cited 5x). Used for: precedent for releasing weights + data + code (fully open); instability/loss-spike diagnosis and stabilization techniques; benchmark definition or evaluation methodology/harness. Role(s): Fully open model / precedent, Training stability / optimization, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing; Deep Dive: \diveAnnealing > \dolminos: High Quality Sources; Introduction; \olmotoo Family Files: neurips_2023.tex
- `openai2024midtraining` — *Introducing improvements to the fine-tuning API and expanding our custom models program, 4 2024* (2024, cited 2x). Used for: evidence for staged training, LR schedules, or end-of-training curricula. Role(s): Training recipe / curriculum. Sections: Deep Dive: \diveAnnealing; \olmotoo Family > Base Model Training Recipe > Stage 2: Mid-training Files: neurips_2023.tex
- `openlm` — *open\_lm: a minimal but performative language modeling (lm) repository, 2023* (2023, cited 1x). Used for: instability/loss-spike diagnosis and stabilization techniques; systems/infra/training-stack reference. Role(s): Training stability / optimization, Infrastructure / systems. Sections: Deep Dive: \diveStability > Model Initialization Files: neurips_2023.tex
- `palm` — *Palm: Scaling language modeling with pathways* (2022, cited 3x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); instability/loss-spike diagnosis and stabilization techniques; benchmark definition or evaluation methodology/harness. Role(s): Scaling laws / compute framing, Training stability / optimization, Evaluation benchmark / methodology. Sections: Deep Dive: \diveStability > Architecture Improvements > Z-Loss; \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `paster2023openwebmath` — *Openwebmath: An open dataset of high-quality mathematical web text, 2023* (2023, cited 4x). Used for: dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Math; Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > MathCoder2-Synthetic; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `patterson2021carbonemissionslargeneural` — *Carbon emissions and large neural network training, 2021* (2021, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `penedo2024fineweb` — *The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale* (2024, cited 1x). Used for: dataset or data-quality/filtering/dedup method. Role(s): Data / preprocessing / filtering. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > High quality web Files: neurips_2023.tex
- `peS2o` — *peS2o (Pretraining Efficiently on S2ORC) Dataset, 2023* (2023, cited 3x). Used for: tokenizer/vocabulary design context; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Tokenizer / vocabulary, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Academic, encyclopedic and other reference content; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `pile` — *The pile: An 800gb dataset of diverse text for language modeling* (2021, cited 1x). Used for: instability/loss-spike diagnosis and stabilization techniques. Role(s): Training stability / optimization. Sections: Deep Dive: \diveStability > Model Initialization > Gradient and activation growth Files: neurips_2023.tex
- `PyTorch2` — *Pytorch 2: Faster machine learning through dynamic python bytecode transformation and graph compilation* (2024, cited 1x). Used for: systems/infra/training-stack reference. Role(s): Infrastructure / systems. Sections: Deep Dive: \diveInfra > Maximizing hardware utilization > Taking advantage of compilation Files: neurips_2023.tex
- `pytorch2024cuda` — *CUDA semantics* (2024, cited 1x). Used for: systems/infra/training-stack reference. Role(s): Infrastructure / systems. Sections: Deep Dive: \diveInfra > Maximizing hardware utilization > Minimizing host-device syncs Files: neurips_2023.tex
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024, cited 5x). Used for: external model baseline and/or source of public recipes; benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Post-training / alignment. Sections: Additional Hyperparameters; Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > DolminoSynthMath; \olmotoo Family > Evaluation and Results Files: appendix.tex, neurips_2023.tex
- `rafailov2024direct` — *Direct preference optimization: Your language model is secretly a reward model* (2024, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Deep Dive: \divePost Files: neurips_2023.tex
- `rajpurkar-etal-2016-squad` — *SQuAD: 100,000+ questions for machine comprehension of text* (2016, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval > Generative tasks Files: appendix.tex
- `reddy-etal-2019-coqa` — *CoQA: A conversational question answering challenge* (2019, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval > Generative tasks Files: appendix.tex
- `RMSNorm` — *Root mean square layer normalization* (2019, cited 1x). Used for: origin/reference for an architecture or optimization component. Role(s): Architecture / optimization component. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `Sakaguchi_Le_Bras_Bhagavatula_Choi_2020` — *WinoGrande: An adversarial winograd schema challenge at scale* (2020, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval Files: appendix.tex
- `scalingvisiontransformers22` — *Scaling vision transformers to 22 billion parameters, 2023a* (2023a, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); origin/reference for an architecture or optimization component. Role(s): Scaling laws / compute framing, Architecture / optimization component. Sections: Deep Dive: \diveStability > Architecture Improvements > Reordered norm and QK-norm Files: neurips_2023.tex
- `schulman2017proximal` — *Proximal policy optimization algorithms* (2017, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Deep Dive: \divePost > Reinforcement Learning with Verifiable Rewards (RLVR) Files: neurips_2023.tex
- `Shaib2024DetectionAM` — *Detection and measurement of syntactic templates in generated text* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Introduction Files: neurips_2023.tex
- `shao2024deepseekmath` — *Deepseekmath: Pushing the limits of mathematical reasoning in open language models* (2024, cited 1x). Used for: external model baseline and/or source of public recipes; benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Post-training / alignment. Sections: Deep Dive: \divePost > Reinforcement Learning with Verifiable Rewards (RLVR) Files: neurips_2023.tex
- `Shazeer2020GLUVI` — *Glu variants improve transformer* (2020, cited 1x). Used for: origin/reference for an architecture or optimization component. Role(s): Architecture / optimization component. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024, cited 4x). Used for: precedent for releasing weights + data + code (fully open); tokenizer/vocabulary design context; dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Fully open model / precedent, Tokenizer / vocabulary, Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Academic, encyclopedic and other reference content; Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Instruction data and Q\&A pairs; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `spikenomore` — *Spike no more: Stabilizing the pre-training of large language models, 2024* (2024, cited 2x). Used for: instability/loss-spike diagnosis and stabilization techniques. Role(s): Training stability / optimization. Sections: Deep Dive: \diveStability > Hyperparameter Improvements > Weight decay on embeddings Files: neurips_2023.tex
- `Su2021RoFormerET` — *Roformer: Enhanced transformer with rotary position embedding* (2021, cited 1x). Used for: origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques. Role(s): Architecture / optimization component, Training stability / optimization. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `suzgun2022challengingbigbenchtaskschainofthought` — *Challenging big-bench tasks and whether chain-of-thought can solve them, 2022* (2022, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks; \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex
- `swin2` — *Swin transformer v2: Scaling up capacity and resolution* (2021, cited 2x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); origin/reference for an architecture or optimization component; systems/infra/training-stack reference. Role(s): Scaling laws / compute framing, Architecture / optimization component, Infrastructure / systems. Sections: Deep Dive: \diveStability > Architecture Improvements > Reordered norm and QK-norm; \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `tao2024scaling` — *Scaling laws with vocabulary: Larger models deserve larger vocabularies* (2024, cited 2x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); tokenizer/vocabulary design context; benchmark definition or evaluation methodology/harness. Role(s): Scaling laws / compute framing, Tokenizer / vocabulary, Evaluation benchmark / methodology. Sections: \olmotoo Family > Tokenizer Files: neurips_2023.tex
- `together2023redpajama` — *RedPajama: An open source recipe to reproduce LLaMA training dataset, 2023* (2023, cited 3x). Used for: external model baseline and/or source of public recipes; dataset or data-quality/filtering/dedup method. Role(s): Open-weight model / baseline, Data / preprocessing / filtering. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Academic, encyclopedic and other reference content; \olmotoo Family > Base Model Data > Pretraining data: \olmomix Files: neurips_2023.tex, tables/stage_1_data.tex
- `touvron2023llama` — *Llama 2: Open foundation and fine-tuned chat models* (2023, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Files: tables/environmental_impact.tex
- `vaswani2017attention` — *Attention is all you need* (2017, cited 2x). Used for: origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques; benchmark definition or evaluation methodology/harness. Role(s): Architecture / optimization component, Training stability / optimization, Evaluation benchmark / methodology. Sections: \olmotoo Family > Model Architecture Files: neurips_2023.tex
- `wang2023mathpile` — *Generative ai for math: Part i -- mathpile: A billion-token-scale pretraining corpus for math* (2023b, cited 1x). Used for: tokenizer/vocabulary design context; dataset or data-quality/filtering/dedup method. Role(s): Tokenizer / vocabulary, Data / preprocessing / filtering. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Math Files: neurips_2023.tex
- `wang2023rail` — *Rail-only: A low-cost high-performance network for training llms with trillion parameters* (2023a, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveInfra > Clusters > Jupiter > Interconnect Files: neurips_2023.tex
- `wang2024mathcoder` — *Mathcoder: Seamless code integration in LLMs for enhanced mathematical reasoning* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > MathCoder2-Synthetic Files: neurips_2023.tex
- `wang2024mmlu` — *Mmlu-pro: A more robust and challenging multi-task language understanding benchmark* (2024, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks Files: appendix.tex
- `wei2021flan` — *Finetuned language models are zero-shot learners* (2021, cited 1x). Used for: dataset or data-quality/filtering/dedup method; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Data / preprocessing / filtering, Post-training / alignment. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Instruction data and Q\&A pairs Files: neurips_2023.tex
- `wei2022chain` — *Chain-of-thought prompting elicits reasoning in large language models* (2022, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex, tables/eval-post.tex
- `wei2023chainofthoughtpromptingelicitsreasoning` — *Chain-of-thought prompting elicits reasoning in large language models, 2023* (2023, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks Files: appendix.tex
- `wriestimatingwater` — *Guidance for calculating water use embedded in purchased electricity, 2020* (2020, cited 1x). Used for: systems/infra/training-stack reference. Role(s): Infrastructure / systems. Sections: Deep Dive: \diveInfra > Environmental Impact Files: neurips_2023.tex
- `yang2024qwen2` — *Qwen2 technical report* (2024a, cited 1x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Introduction Files: neurips_2023.tex
- `yang2024spectral` — *A spectral condition for feature learning, 2024b* (2024b, cited 3x). Used for: evidence for staged training, LR schedules, or end-of-training curricula; compute/performance scaling context (tokens, FLOPs, Pareto); instability/loss-spike diagnosis and stabilization techniques. Role(s): Training recipe / curriculum, Scaling laws / compute framing, Training stability / optimization. Sections: Deep Dive: \diveStability > Model Initialization > Hyperparameter transfer across width Files: neurips_2023.tex
- `yang2025qwen3technicalreport` — *Qwen3 technical report* (2025, cited 2x). Used for: external model baseline and/or source of public recipes; compute/performance scaling context (tokens, FLOPs, Pareto); instability/loss-spike diagnosis and stabilization techniques; benchmark definition or evaluation methodology/harness. Role(s): Open-weight model / baseline, Scaling laws / compute framing, Training stability / optimization, Evaluation benchmark / methodology. Sections: \olmotoo Family > Base Model Training Recipe > Stage 1: Pretraining; \olmotoo Family > Evaluation and Results Files: neurips_2023.tex
- `young2024yi` — *Yi: Open foundation models by 01. ai* (2024, cited 3x). Used for: external model baseline and/or source of public recipes. Role(s): Open-weight model / baseline. Sections: Additional Hyperparameters; Introduction Files: appendix.tex, neurips_2023.tex
- `yu2023metamath` — *Metamath: Bootstrap your own mathematical questions for large language models* (2023, cited 1x). Used for: dataset or data-quality/filtering/dedup method; benchmark definition or evaluation methodology/harness. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Deep Dive: \diveAnnealing > \dolminos: Math Mix > Math Sources > ProofPile OWM-Filtered Files: neurips_2023.tex
- `zamba2_model` — *The zamba2 suite: Technical report* (2024, cited 1x). Used for: compute/performance scaling context (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology/harness. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology. Sections: \olmotoo Family > Evaluation and Results Files: neurips_2023.tex
- `zellers-etal-2019-hellaswag` — *HellaSwag: Can a machine really finish your sentence?* (2019, cited 1x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval Files: appendix.tex
- `Zhang2019ImprovingDT` — *Improving deep transformer with depth-scaled initialization and merged attention* (2019, cited 2x). Used for: origin/reference for an architecture or optimization component; instability/loss-spike diagnosis and stabilization techniques; systems/infra/training-stack reference. Role(s): Architecture / optimization component, Training stability / optimization, Infrastructure / systems. Sections: Deep Dive: \diveStability; Deep Dive: \diveStability > Model Initialization Files: neurips_2023.tex
- `zhang2024automathtext` — *Autonomous data selection with language models for mathematical texts* (2024b, cited 1x). Used for: dataset or data-quality/filtering/dedup method. Role(s): Data / preprocessing / filtering. Sections: Deep Dive: \diveAnnealing > \dolminos: High Quality Sources > Math Files: neurips_2023.tex
- `zhang2024mapneo` — *Map-neo: Highly capable and transparent bilingual large language model series* (2024a, cited 1x). Used for: precedent for releasing weights + data + code (fully open). Role(s): Fully open model / precedent. Sections: Introduction Files: neurips_2023.tex
- `zheng2023judging` — *Judging llm-as-a-judge with mt-bench and chatbot arena* (2023, cited 1x). Used for: post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Post-training / alignment. Sections: Deep Dive: \divePost > Preference Finetuning (PreFT) with DPO Files: neurips_2023.tex
- `zhong-etal-2024-agieval` — *AGIEval: A human-centric benchmark for evaluating foundation models* (2024, cited 2x). Used for: benchmark definition or evaluation methodology/harness. Role(s): Evaluation benchmark / methodology. Sections: \olmotoo Evaluation Framework > Base Model Eval; \olmotoo Evaluation Framework > Base Model Eval > Held-out tasks Files: appendix.tex
- `zhou2023instructionfollowingevaluationlargelanguage` — *Instruction-following evaluation for large language models, 2023* (2023, cited 1x). Used for: benchmark definition or evaluation methodology/harness; post-training method (SFT/DPO/RL*) or alignment dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment. Sections: \olmotoo Evaluation Framework > Instruct Model Eval > Instruct tasks Files: appendix.tex

