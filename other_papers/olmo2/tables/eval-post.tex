\begin{table}[h]
\centering
\setlength\tabcolsep{5pt}
\begin{small}
\adjustbox{max width=\linewidth}{
\begin{tabular}{{@{}ll C{0.7cm} R{1.4cm} C{1cm} C{2cm} c@{}}}
\toprule
 \textbf{Category} & \textbf{Benchmark} & \textbf{CoT} & \textbf{\# Shots} & \textbf{Chat} & \textbf{Multiturn ICL} & \textbf{Metric} \\\midrule
\rowcolor{ai2offwhite}  Knowledge Recall & MMLU & \cmark & 0 & \cmark & \xmark & EM \\
\rowcolor{ai2offwhite} & PopQA & \xmark & 15 & \cmark & \cmark & EM \\
\rowcolor{ai2offwhite} & TruthfulQA & \xmark & 6 & \cmark & \xmark & MC2 \\
  Reasoning & BigBenchHard & \cmark & 3 & \cmark & \cmark & EM \\
  & DROP & \xmark & 3 & \xmark & N/A & F1 \\
\rowcolor{ai2offwhite}  Math & GSM8K & \cmark & 8 & \cmark & \cmark & EM \\
\rowcolor{ai2offwhite}   & MATH & \cmark & 4 & \cmark & \cmark & Flex EM \\
   Instruction Following & IFEval & \xmark & 0 & \cmark & N/A & Pass@1 (prompt; loose) \\
  & AlpacaEval 2 & \xmark & 0 & \cmark & N/A & LC Winrate \\
 \rowcolor{ai2offwhite}  Safety & \tulu Safety & \xmark & 0 & \cmark & N/A & Average$^*$ \\
\bottomrule
\end{tabular}}
\end{small}
\vspace{3pt}
\caption{
The \olmotoo Instruct Evaluation Regime (Adapted from \citet{lambert2024tulu3}): settings for development ({\bf{top}}) and unseen ({\bf{bottom}}) portions of the evaluation suite. {\bf{CoT}} are evaluations run with chain of thought prompting~\citep{wei2022chain}.
{\bf{\# shots}} is the number of in-context examples in the evaluation template.
{\bf{Chat}} indicates whether we use a chat template while prompting the model.
{\bf{Multiturn ICL}} indicates that we present each in-context example as a separate turn in a conversation (applicable only when a chat template is used and \# Shots is not 0).
$^*$Average over multiple sub-evaluations---full details of the safety evaluation are in \citet{lambert2024tulu3}.
}
\label{tab:eval-post}
\end{table}
