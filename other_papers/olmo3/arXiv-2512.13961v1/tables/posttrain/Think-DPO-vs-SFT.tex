\begin{table}[tbp]
\centering
\small
\begin{tabular}{@{}l >{\columncolor{ai2pink!18}}c cccccccccc@{}}%
\toprule
& \multicolumn{11}{c}{\textbf{Subset of \olmothreethinking Benchmarks}} \\
\cmidrule(lr){2-12}
\textbf{Name} & \cellcolor{ai2pink!18}\textbf{Avg.} & \textbf{MMLU} & \textbf{BBH} & \textbf{GPQA} & \textbf{Zebra} & \textbf{AGI} & \textbf{AIME25} & \textbf{AIME24} & \textbf{CHE} & \textbf{LCB} & \textbf{IFEval} \\
\midrule
Qwen3 32B (chosen) & 83.2 & 88.8 & 90.6 & 64.7 & 78.2 & 90.2 & 71.0 & 80.3 & 90.9 & 89.6 & 87.4 \\
Qwen3 0.6B (rejected) & 35.1 & 55.8 & 41.5 & 27.2 & 29.8 & 59.2 & 15.2 & 11.2 & 14.8 & 34.4 & 62.3 \\
\midrule
Dev. 7B SFT ckpt & 70.3 & {\bf 76.1} & {\bf 83.9} & 45.1 & 56.5 & 76.4 & 58.8 & 71.0 & 88.1 & 67.0 & {\bf 79.7} \\
Cont. SFT on chosen & 64.5 & 72.6 & 80.2 & 40.2 & 49.8 & 73.9 & 52.8 & 61.0 & 83.4 & 55.1 & 76.0 \\
Delta learning & {\bf 72.9} & 75.5 & 82.8 & {\bf 48.4} & {\bf 60.9} & {\bf 79.7} & {\bf 66.3} & {\bf 75.7} & {\bf 91.5} & {\bf 72.6} & 75.2 \\
\bottomrule
\end{tabular}
\caption{\textbf{The delta between chosen and rejected responses is critical}. Supervised finetuning directly on the chosen responses generated by Qwen3-32B Thinking hurts the Initial SFT model. In contrast, DPO tuning to prefer the 32B responses over weaker Qwen3-0.6B Thinking responses yields strong gains across math and code reasoning.}
\label{tab:dpo_sftchosen}
\end{table}
