\begin{table}[t]
\centering
\footnotesize
\setlength\tabcolsep{5pt}
\renewcommand{\arraystretch}{0.95}
\adjustbox{max width=\linewidth}{
{\fontsize{8}{8}\selectfont
\begin{NiceTabular}{@{}Hl
P{38pt}C{38pt}C{38pt}C{38pt}|
C{33pt}C{33pt}C{33pt}C{33pt}C{33pt}C{33pt}@{}}
\toprule
& & \multicolumn{4}{c}{\quad \quad \textbf{\texttt{Fully-Open Models}}} & \multicolumn{6}{c}{\textbf{\texttt{Open-weight Models}}} \\
\textbf{Skill} &
& \textbf{OLMo 3.1 32B Think} & \textbf{OLMo 2 Instruct 32B} & \textbf{Apertus Instruct 70B} & \textbf{LLM360 K2-V2 Instruct 70B} & \textbf{Qwen 3 32B} & \textbf{Qwen 3 VL 32B Think} & \textbf{Qwen 2.5 32B} & \textbf{Gemma 3 27B} & \textbf{Gemma 2 27B} & \textbf{DS-R1 32B} \\
\midrule

\rowcolor{midgrey} -- & \textbf{Math} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{MATH} & 96.2 & 49.2 & 36.2 & 94.5 & 95.4 & 96.7 & 80.2 & 87.4 & 51.5 & 92.6 \\
\rowcolor{lightgrey} -- & \metric{AIME 2024} & 80.6 & 4.6 & 0.3 & 78.4 & 80.8 & 86.3 & 15.7 & 28.9 & 4.7 & 70.3 \\
\rowcolor{lightgrey} -- & \metric{AIME 2025} & 78.1 & 0.9 & 0.1 & 70.3 & 70.9 & 78.8 & 13.4 & 22.9 & 0.9 & 56.3 \\
\rowcolor{lightgrey} -- & \metric{OMEGA} & 53.4 & 9.8 & 5.6 & 46.1 & 47.7 & 50.8 & 19.2 & 24.0 & 9.1 & 38.9 \\
\midrule

\rowcolor{midgrey} -- & \textbf{Reasoning} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{BigBenchHard} & 88.6 & 65.6 & 57.0 & 87.6 & 90.6 & 91.1 & 80.9 & 82.4 & 66.0 & 89.7 \\
\rowcolor{lightgrey} -- & \metric{ZebraLogic} & 80.1 & 13.3 & 9.0 & 79.2 & 88.3 & 96.1 & 24.1 & 24.8 & 17.2 & 69.4 \\
\rowcolor{lightgrey} -- & \metric{AGI Eval English} & 89.2 & 68.4 & 61.7 & 89.6 & 90.0 & 92.2 & 78.9 & 76.9 & 70.9 & 88.1 \\
\midrule

\rowcolor{midgrey} -- & \textbf{Coding} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{HumanEvalPlus} & 91.5 & 44.4 & 42.9 & 88.0 & 91.2 & 90.6 & 82.6 & 79.2 & 67.5 & 92.3 \\
\rowcolor{lightgrey} -- & \metric{MBPP+} & 68.3 & 49.0 & 45.8 & 66.0 & 70.6 & 66.2 & 66.6 & 65.7 & 61.2 & 70.1 \\
\rowcolor{lightgrey} -- & \metric{LiveCodeBench v3} & 83.3 & 10.6 & 9.7 &  78.4 & 90.2 & 84.8 & 49.9 & 39.0 & 28.7 & 79.5 \\
\midrule

\rowcolor{midgrey} -- & \textbf{IF} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{IFEval} & 93.8 & 85.8 & 70.4 & 68.7 & 86.5 & 85.5 & 81.9 & 85.4 & 62.1 & 78.7 \\
\rowcolor{lightgrey} -- & \metric{IFBench} & 68.1 & 36.4 & 26.0 & 46.3 & 37.3 & 55.1 & 36.7 & 31.3 & 27.8 & 23.8 \\
\midrule

\rowcolor{midgrey} -- & \textbf{Knowledge \& QA} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{MMLU} & 86.4 & 77.1 & 70.2 & 88.4 & 88.8 & 90.1 & 84.6 & 74.6 & 76.1 & 88.0 \\
\rowcolor{lightgrey} -- & \metric{PopQA} & 30.9 & 37.2 & 33.6 & 32.2 & 30.7 & 32.2 & 28.0 & 30.2 & 30.4 & 26.7 \\
\rowcolor{lightgrey} -- & \metric{GPQA} & 57.5& 36.4 & 27.9 & 64.0 & 67.3 & 67.4 & 44.6 & 45.0 & 39.9 & 61.8 \\
\midrule

\rowcolor{midgrey} -- & \textbf{Chat} & & & & & & & & & & \\
\rowcolor{lightgrey} -- & \metric{AlpacaEval 2 LC} & 69.1 & 38.0 & 19.9 &  - & 75.6 & 80.9 & 81.9 & 65.5 & 39.8 & 26.2 \\

\bottomrule

\end{NiceTabular}}}
\caption{\textbf{Results on our flagship model \olmothreeonethink~32B} on our post-training evaluation suite. \olmothreeonethink~32B is the best fully-open model at 32B.
}
\label{tab:32b-think-flagship-results}
\end{table}
