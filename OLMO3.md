# OLMo 3 — Reading Notes and Citation Guide

This file summarizes the OLMo 3 paper in `other_papers/olmo3/arXiv-2512.13961v1/` with emphasis on related work and citation intent.

## High-Level Takeaways
- Fully-open “model flow” release: the authors emphasize releasing the *entire lifecycle* (data, code, intermediate checkpoints), not just a final checkpoint.
- Model family includes base models (7B/32B) and multiple post-trained variants: Think, Instruct, and an RL-from-base “RL-Zero” variant.
- Data pipeline is multi-stage: Dolma 3 pretraining mix, Dolmino midtraining mix (reasoning jump-start), Longmino long-context mix (science PDFs/OCR and long-context support), plus Dolci post-training suites (SFT/DPO/RL).
- The paper positions OLMo 3 as a top fully-open alternative to strong open-weight baselines, and discusses algorithmic+infrastructure advances across the pipeline (evaluation, data processing, RL efficiency).

## Related Work Map (Roles → Representative Citations)
These are automatically selected by citation frequency within each role category.

### Fully open model / precedent
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024) — cited 13x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a) — cited 7x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 3x
- `swissai2025apertus` — *Apertus: Democratizing Open and Compliant LLMs for Global Language Environments* (2025) — cited 2x
- `liu2023llm360` — *Llm360: Towards fully transparent open-source llms* (2023c) — cited 1x

### Open-weight model / baseline
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `team2025gemma3` — *Gemma 3 technical report, 2025* (2025) — cited 4x
- `guo2025deepseek` — *Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning* (2025) — cited 3x
- `gpt4` — *GPT-4 technical report* (2023b) — cited 3x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 3x
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 3x
- `deepseekv3` — *Deepseek-v3 technical report, 2025* (2025) — cited 2x
- `bercovich2025llamanemotronefficientreasoningmodels` — *Llama-nemotron: Efficient reasoning models, 2025* (2025) — cited 2x
- `guo2024deepseek` — *Deepseek-coder: When the large language model meets programming--the rise of code intelligence* (2024) — cited 2x

### Data / preprocessing / filtering
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025) — cited 17x
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024) — cited 13x
- `geng2025delta` — *The delta learning hypothesis: Preference tuning on weak data can yield strong gains* (2025) — cited 10x
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a) — cited 7x
- `su2025klear` — *Klear-reasoner: Advancing reasoning capability via gradient-preserving clipping policy optimization* (2025c) — cited 6x
- `bakouch2025smollm3` — *SmolLM3: smol, multilingual, long-context reasoner* (2025) — cited 5x
- `poznanski2025olmocr` — *olmOCR: Unlocking trillions of tokens in pdfs with vision language models* (2025a) — cited 5x
- `weborganizer` — *Organize the web: Constructing domains enhances pre-training data curation, 2025* (2025) — cited 5x

### Long-context / document understanding
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a) — cited 7x
- `bakouch2025smollm3` — *SmolLM3: smol, multilingual, long-context reasoner* (2025) — cited 5x
- `poznanski2025olmocr` — *olmOCR: Unlocking trillions of tokens in pdfs with vision language models* (2025a) — cited 5x
- `weborganizer` — *Organize the web: Constructing domains enhances pre-training data curation, 2025* (2025) — cited 5x
- `allal2025smollm2smolgoesbig` — *Smollm2: When smol goes big -- data-centric training of a small language model, 2025* (2025) — cited 5x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `team2025gemma3` — *Gemma 3 technical report, 2025* (2025) — cited 4x
- `lozhkov2024starcoder` — *Starcoder 2 and the stack v2: The next generation* (2024) — cited 4x
- `kopf2024openassistant` — *Openassistant conversations-democratizing large language model alignment* (2024) — cited 4x
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 3x

### Reasoning / thinking
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025) — cited 17x
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024) — cited 13x
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `geng2025delta` — *The delta learning hypothesis: Preference tuning on weak data can yield strong gains* (2025) — cited 10x
- `guha2025openthoughts` — *Openthoughts: Data recipes for reasoning models* (2025a) — cited 9x
- `primeintellect2025synthetic2` — *Synthetic-2* (2025) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `liu2025understanding` — *Understanding r1-zero-like training: A critical perspective* (2025b) — cited 6x
- `su2025klear` — *Klear-reasoner: Advancing reasoning capability via gradient-preserving clipping policy optimization* (2025c) — cited 6x
- `ahmad2025opencodereasoning` — *Opencodereasoning: Advancing data distillation for competitive coding* (2025) — cited 6x

### Tool use / function calling
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024) — cited 13x
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `bakouch2025smollm3` — *SmolLM3: smol, multilingual, long-context reasoner* (2025) — cited 5x
- `weborganizer` — *Organize the web: Constructing domains enhances pre-training data curation, 2025* (2025) — cited 5x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 3x
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024) — cited 3x
- `suzgun2022challenging` — *Challenging big-bench tasks and whether chain-of-thought can solve them* (2022) — cited 3x
- `drtulu` — *DR Tulu: Reinforcement learning with evolving rubrics for deep research, 2025a* (2025a) — cited 2x
- `patil2025bfcl` — *The berkeley function calling leaderboard (bfcl): From tool use to agentic evaluation of large language models* (2025) — cited 2x

### Evaluation benchmark / methodology
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 21x
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025) — cited 17x
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a) — cited 7x
- `lewkowycz2022solving` — *Solving quantitative reasoning problems with language models* (2022) — cited 6x
- `hendryckstest2021` — *Measuring massive multitask language understanding* (2021b) — cited 6x
- `jiang2024wildteaming` — *Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models* (2024) — cited 5x
- `allal2025smollm2smolgoesbig` — *Smollm2: When smol goes big -- data-centric training of a small language model, 2025* (2025) — cited 5x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `shao2025spuriousrewardsrethinkingtraining` — *Spurious rewards: Rethinking training signals in rlvr, 2025b* (2025b) — cited 4x

### Post-training / alignment / RL
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 21x
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025) — cited 17x
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `geng2025delta` — *The delta learning hypothesis: Preference tuning on weak data can yield strong gains* (2025) — cited 10x
- `guha2025openthoughts` — *Openthoughts: Data recipes for reasoning models* (2025a) — cited 9x
- `primeintellect2025synthetic2` — *Synthetic-2* (2025) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `liu2025understanding` — *Understanding r1-zero-like training: A critical perspective* (2025b) — cited 6x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `shao2025spuriousrewardsrethinkingtraining` — *Spurious rewards: Rethinking training signals in rlvr, 2025b* (2025b) — cited 4x

### Safety / risk
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 21x
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024) — cited 8x
- `jiang2024wildteaming` — *Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models* (2024) — cited 5x
- `kopf2024openassistant` — *Openassistant conversations-democratizing large language model alignment* (2024) — cited 4x
- `guo2025deepseek` — *Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning* (2025) — cited 3x
- `parrish-etal-2022-bbq` — *BBQ: A hand-built bias benchmark for question answering* (2022) — cited 3x
- `brahman2024art` — *The art of saying no: Contextual noncompliance in language models* (2024) — cited 3x
- `wadden2024sciriff` — *Sciriff: A resource to enhance language model instruction-following over scientific literature* (2024) — cited 3x
- `dubois2024length` — *Length-controlled alpacaeval: A simple way to debias automatic evaluators* (2024) — cited 2x
- `kaiyom2024helmsafety` — *HELM safety: Towards standardized safety evaluations of language models, 8 Nov. 2024* (2024) — cited 2x

### Architecture / optimization component
- `allal2025smollm2smolgoesbig` — *Smollm2: When smol goes big -- data-centric training of a small language model, 2025* (2025) — cited 5x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024) — cited 3x
- `peng2023yarnefficientcontextwindow` — *Yarn: Efficient context window extension of large language models, 2023* (2023) — cited 2x
- `heineman2025signalnoiseframeworkreducing` — *Signal and noise: A framework for reducing uncertainty in language model evaluation, 2025* (2025) — cited 2x
- `vllm` — *Efficient memory management for large language model serving with pagedattention* (2023) — cited 2x
- `nvidia2025nvidianemotronnano2` — *NVIDIA Nemotron Nano 2: An accurate and efficient hybrid mamba-transformer reasoning model, 2025* (2025) — cited 1x
- `prolong` — *How to train long-context language models (effectively)* (2025) — cited 1x
- `wu2025longattn` — *LongAttn: Selecting long-context training data via token-level attention, 2025b* (2025b) — cited 1x
- `su2024roformer` — *Roformer: Enhanced transformer with rotary position embedding* (2024) — cited 1x

### Scaling laws / compute framing
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `guha2025openthoughts` — *Openthoughts: Data recipes for reasoning models* (2025a) — cited 9x
- `primeintellect2025synthetic2` — *Synthetic-2* (2025) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `team2025gemma3` — *Gemma 3 technical report, 2025* (2025) — cited 4x
- `olmes` — *Olmes: A standard for language model evaluations* (2024b) — cited 4x
- `hu2025open` — *Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model* (2025) — cited 3x
- `deepscaler2025` — *Deepscaler: Surpassing o1-preview with a 1.5b model by scaling rl* (2025a) — cited 3x
- `parrish-etal-2022-bbq` — *BBQ: A hand-built bias benchmark for question answering* (2022) — cited 3x

### Tokenizer / vocabulary
- `poznanski2025olmocr` — *olmOCR: Unlocking trillions of tokens in pdfs with vision language models* (2025a) — cited 5x
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024) — cited 3x
- `gpt4` — *GPT-4 technical report* (2023b) — cited 3x
- `lee2022deduplicatingtrainingdatamakes` — *Deduplicating training data makes language models better, 2022* (2022) — cited 2x
- `wu2025longattn` — *LongAttn: Selecting long-context training data via token-level attention, 2025b* (2025b) — cited 1x
- `gpt35` — *GPT-3.5 turbo, 2023a* (2023a) — cited 1x

### Infrastructure / systems
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024) — cited 8x
- `lozhkov2024starcoder` — *Starcoder 2 and the stack v2: The next generation* (2024) — cited 4x
- `parrish-etal-2022-bbq` — *BBQ: A hand-built bias benchmark for question answering* (2022) — cited 3x
- `yao2025offpolicy` — *Your efficient rl framework secretly brings you off-policy rl training, Aug. 2025* (2025) — cited 3x
- `mazeika2024harmbench` — *Harmbench: A standardized evaluation framework for automated red teaming and robust refusal* (2024) — cited 2x
- `shen2024anything` — *" do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models* (2024) — cited 2x
- `rottger2023xstest` — *Xstest: A test suite for identifying exaggerated safety behaviours in large language models* (2023) — cited 2x
- `toxigen` — *Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection* (2022) — cited 2x
- `drtulu` — *DR Tulu: Reinforcement learning with evolving rubrics for deep research, 2025a* (2025a) — cited 2x
- `vllm` — *Efficient memory management for large language model serving with pagedattention* (2023) — cited 2x

## Most-Frequent Citations (Global)
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024) — cited 21x
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025) — cited 17x
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024) — cited 13x
- `qwen3` — *Qwen3 technical report* (2025a) — cited 11x
- `geng2025delta` — *The delta learning hypothesis: Preference tuning on weak data can yield strong gains* (2025) — cited 10x
- `guha2025openthoughts` — *Openthoughts: Data recipes for reasoning models* (2025a) — cited 9x
- `primeintellect2025synthetic2` — *Synthetic-2* (2025) — cited 8x
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024) — cited 8x
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a) — cited 7x
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a) — cited 7x
- `liu2025understanding` — *Understanding r1-zero-like training: A critical perspective* (2025b) — cited 6x
- `su2025klear` — *Klear-reasoner: Advancing reasoning capability via gradient-preserving clipping policy optimization* (2025c) — cited 6x
- `ahmad2025opencodereasoning` — *Opencodereasoning: Advancing data distillation for competitive coding* (2025) — cited 6x
- `lewkowycz2022solving` — *Solving quantitative reasoning problems with language models* (2022) — cited 6x
- `hendryckstest2021` — *Measuring massive multitask language understanding* (2021b) — cited 6x
- `bakouch2025smollm3` — *SmolLM3: smol, multilingual, long-context reasoner* (2025) — cited 5x
- `poznanski2025olmocr` — *olmOCR: Unlocking trillions of tokens in pdfs with vision language models* (2025a) — cited 5x
- `jiang2024wildteaming` — *Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models* (2024) — cited 5x
- `weborganizer` — *Organize the web: Constructing domains enhances pre-training data curation, 2025* (2025) — cited 5x
- `allal2025smollm2smolgoesbig` — *Smollm2: When smol goes big -- data-centric training of a small language model, 2025* (2025) — cited 5x
- `moshkov2025aimo2` — *AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset* (2025) — cited 5x
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025) — cited 4x
- `shao2025spuriousrewardsrethinkingtraining` — *Spurious rewards: Rethinking training signals in rlvr, 2025b* (2025b) — cited 4x
- `Sun2025OMEGACL` — *Omega: Can llms reason outside the box in math? evaluating exploratory, compositional, and transformative generalization* (2025) — cited 4x
- `zeng2025acecoder` — *Acecoder: Acing coder rl via automated test-case synthesis* (2025a) — cited 4x

## Annotated Reference Index (All Cited References)
Each entry lists the BibTeX key, reference title, a coarse “used for” rationale, coarse roles, and where it appears in the TeX sources.

- `Abdin2024Phi4TR` — *Phi-4 technical report* (2024, cited 1x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Reasoning / thinking. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs Files: section8-appendix-posttrain.tex
- `ACKERMAN2017607` — *Meta-reasoning: Monitoring and control of thinking and reasoning* (2017, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `adler2024nemotron` — *Nemotron-4 340b technical report* (2024, cited 1x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Reasoning / thinking. Sections: Post-Training Additional Evaluation Details > General Evaluation Settings Files: section8-appendix-posttrain.tex
- `agarwal2025gpt` — *gpt-oss-120b \& gpt-oss-20b model card* (2025, cited 1x). Used for: background context. Role(s): General reference. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs Files: section8-appendix-posttrain.tex
- `aggarwal2025l1controllinglongreasoning` — *L1: Controlling how long a reasoning model thinks with reinforcement learning, 2025* (2025, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Data / preprocessing / filtering, Reasoning / thinking. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details > Verifiers Files: section-4-think.tex
- `ahmad2025opencodereasoning` — *Opencodereasoning: Advancing data distillation for competitive coding* (2025, cited 6x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; Post-Training Additional Data Details > Coding Data Synthesis Pipeline; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces; \olmothreethinking > Preference Tuning with Delta Learning; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-3-base-kyle.tex, section-4-think.tex, section8-appendix-base.tex, section8-appendix-posttrain.tex
- `ainslie2023gqatraininggeneralizedmultiquery` — *Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023* (2023, cited 1x). Used for: architecture/optimization component referenced or adapted. Role(s): Architecture / optimization component. Files: tables/base_training/combined_model_specs.tex
- `akter2024mindmathinformedsynthetic` — *Mind: Math informed synthetic dialogues for pretraining llms, 2024* (2024, cited 1x). Used for: background context. Role(s): General reference. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > TinyMATH Files: section8-appendix-base.tex
- `allal2025smollm2smolgoesbig` — *Smollm2: When smol goes big -- data-centric training of a small language model, 2025* (2025, cited 5x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; architecture/optimization component referenced or adapted; benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Architecture / optimization component, Evaluation benchmark / methodology, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Midtraining > Code Capabilities; Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > CraneMath; \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Code; \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Math; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Math capabilities Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `alpaca_eval` — *Alpacaeval: An automatic evaluator of instruction-following models* (2023b, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `anthropic-claude4-systemcard` — *System card: Claude opus 4 \& claude sonnet 4* (2025, cited 1x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview Files: section8-appendix-posttrain.tex
- `Asai2024OpenScholarSS` — *Openscholar: Synthesizing scientific literature with retrieval-augmented lms* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Long-context / document understanding. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `austin2021program` — *Program synthesis with large language models* (2021, cited 3x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Easy suite Files: section8-appendix-base.tex, tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `azar2023generaltheoreticalparadigmunderstand` — *A general theoretical paradigm to understand learning from human preferences, 2023* (2023, cited 1x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: \olmothreeinstruct > Key Findings > The ideal amount of preference data depends on the downstream task Files: section-5-instruct-pradeep.tex
- `azerbayev2023llemma` — *Llemma: An open language model for mathematics, 2023* (2023, cited 1x). Used for: long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Math Files: section-3-base-kyle.tex
- `bakouch2025smollm3` — *SmolLM3: smol, multilingual, long-context reasoner* (2025, cited 5x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines; tool-use or function-calling interface/eval context. Role(s): Data / preprocessing / filtering, Reasoning / thinking, Long-context / document understanding, Tool use / function calling. Sections: Model Flow for \olmothree > Base Model Training > Data curriculum; Stage 3: Long-context Extension > High variance in open-model recipes; \olmothreebase > Stage 1: Pretraining; \olmothreethinking > Preference Tuning with Delta Learning; \olmothreethinking > Preference Tuning with Delta Learning > \dolcithink-DPO: Preference Data Creation > Step 1: sourcing prompts and contrastive completions Files: LC-luca-YOUMAYTOUCH.tex, section-2-ake.tex, section-3-base-kyle.tex, section-4-think.tex
- `bavarian2022efficient` — *Efficient training of language models to fill in the middle* (2022, cited 4x). Used for: benchmark definition or evaluation methodology; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Evaluation Details > Expanding OLMES tasks Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex
- `beltagy2020longformer` — *Longformer: The long-document transformer* (2020, cited 1x). Used for: architecture/optimization component referenced or adapted. Role(s): Architecture / optimization component. Sections: \olmothreebase > Modeling and Architecture > Architecture Files: section-3-base-kyle.tex
- `bercovich2025llamanemotronefficientreasoningmodels` — *Llama-nemotron: Efficient reasoning models, 2025* (2025, cited 2x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Existing thinking traces; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, section8-appendix-base.tex
- `bertsch2026cracks` — *Cracks in the foundation: Architectural choices impact long context extension, 2026* (2026, cited 1x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Long-context / document understanding. Sections: Stage 3: Long-context Extension > \olmothree long-context recipe Files: LC-luca-YOUMAYTOUCH.tex
- `bevendorff2018` — *Elastic ChatNoir: Search Engine for the ClueWeb and the Common Crawl* (2018, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Text extraction Files: section-3-base-kyle.tex
- `bfa322bf36e54a4ca19f9a73bee6184b` — *Rational use of cognitive resources in human planning* (2022, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `bhagia2024establishingtaskscalinglaws` — *Establishing task scaling laws via compute-efficient model ladders, 2024* (2024, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Evaluation benchmark / methodology, Long-context / document understanding. Sections: \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex
- `Bisk_Zellers_Le_bras_Gao_Choi_2020` — *PIQA: Reasoning about physical commonsense in natural language* (2020, cited 2x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Bordt2024HowMC` — *How much can we forget about data contamination?* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreebase > Stage 2: Midtraining > Decontamination Files: section-3-base-kyle.tex
- `bragg2025astabench` — *Astabench: Rigorous benchmarking of ai agents with a scientific research suite* (2025, cited 2x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Long-context / document understanding, Tool use / function calling. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Evaluating function calling Files: section-5-instruct-pradeep.tex
- `brahman2024art` — *The art of saying no: Contextual noncompliance in language models* (2024, cited 3x). Used for: safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Safety / risk. Files: tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `cai2025aegisllm` — *Aegisllm: Scaling agentic systems for self-reflective defense in llm security* (2025, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview Files: section8-appendix-posttrain.tex
- `cassano2022multipl` — *Multipl-e: A scalable and extensible approach to benchmarking neural code generation* (2022, cited 4x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Easy suite Files: section8-appendix-base.tex, tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Chatterji2025-fs` — *How people use ChatGPT* (2025, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Reasoning / thinking. Sections: \olmothreeinstruct; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 2: filtering Files: section-4-think.tex, section-5-instruct-pradeep.tex
- `chen2021codex` — *Evaluating large language models trained on code* (2021, cited 3x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Easy suite Files: section8-appendix-base.tex, tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `chen2023extendingcontextwindowlarge` — *Extending context window of large language models via positional interpolation, 2023* (2023, cited 1x). Used for: architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto). Role(s): Architecture / optimization component, Scaling laws / compute framing. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > RoPE extension Files: LC-luca-YOUMAYTOUCH.tex
- `chen2025acereason` — *Acereason-nemotron: Advancing math and code reasoning through reinforcement learning* (2025, cited 2x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Reasoning / thinking. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, tables/posttrain_data/rlvr_data.tex
- `cheng2025revisiting` — *Revisiting reinforcement learning for llm reasoning from a cross-domain perspective, 2025* (2025, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Key Findings > Mixing data yields lower train reward, but not lower downstream performance Files: section-4-think.tex
- `clark-etal-2019-boolq` — *BoolQ: Exploring the surprising difficulty of natural yes/no questions* (2019, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreebase > Experimental Design and Evaluation > Signal-to-Noise Analysis Files: section-3-base-kyle.tex
- `clark2018think` — *Think you have solved question answering? Try ARC, the AI2 reasoning challenge* (2018, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `cobbe2021gsm8k` — *Training verifiers to solve math word problems* (2021, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > TinyMATH Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex
- `CommonCrawl` — *Common Crawl Dataset* (cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method. Role(s): Data / preprocessing / filtering. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `cui2023ultrafeedback` — *UltraFeedback: Boosting language models with scaled ai feedback* (2023, cited 4x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; \olmothreethinking > Preference Tuning with Delta Learning > \dolcithink-DPO: Preference Data Creation > Step 1: sourcing prompts and contrastive completions Files: section-4-think.tex, section8-appendix-posttrain.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `d2025anchored` — *Anchored preference optimization and contrastive revisions: Addressing underspecification in alignment* (2025, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreeinstruct > Key Findings > High contrast in preference pairs drives DPO improvements; \olmothreethinking > Preference Tuning with Delta Learning > Delta Learning Files: section-4-think.tex, section-5-instruct-pradeep.tex
- `dao2023flashattention2` — *FlashAttention-2: Faster attention with better parallelism and work partitioning* (2024, cited 1x). Used for: architecture/optimization component referenced or adapted; training stack / distributed systems / efficiency tooling. Role(s): Architecture / optimization component, Infrastructure / systems. Sections: \olmothreebase > Modeling and Architecture > Training Files: section-3-base-kyle.tex
- `dasigi2021dataset` — *A dataset of information-seeking questions and answers anchored in research papers* (2021, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex
- `dclm` — *Datacomp-lm: In search of the next generation of training sets for language models, 2024a* (2024a, cited 7x). Used for: fully-open precedent (release of weights+data+code) or open-data pipeline reference; dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Evaluation benchmark / methodology, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl; Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl Mixing; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Heuristic filtering; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Text extraction; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `deadly-triad` — *Deep reinforcement learning and the deadly triad* (2018, cited 1x). Used for: background context. Role(s): General reference. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Inflight updates Files: section-4-think.tex
- `deepscaler2025` — *Deepscaler: Surpassing o1-preview with a 1.5b model by scaling rl* (2025a, cited 3x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces; \olmothreerlzero > Key Findings > \olmothreerlzero mix can benchmark challenges in multi-objective RL Files: section-3-base-kyle.tex, section-6-rlzero.tex, section8-appendix-base.tex
- `deepseekv3` — *Deepseek-v3 technical report, 2025* (2025, cited 2x). Used for: external baseline model and/or public recipe reference. Role(s): Open-weight model / baseline. Sections: Model Flow for \olmothree > Costs; Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex, section-2-ake.tex
- `deepseekV31` — *DeepSeek-V3.1 release* (2025, cited 1x). Used for: external baseline model and/or public recipe reference. Role(s): Open-weight model / baseline. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `deepspeed` — *Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters* (2020, cited 1x). Used for: post-training (SFT/DPO/RL*) method or dataset; training stack / distributed systems / efficiency tooling. Role(s): Post-training / alignment / RL, Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Fully asynchronous training Files: section-4-think.tex
- `diao2025climbclusteringbasediterativedata` — *Climb: Clustering-based iterative data mixture bootstrapping for language model pre-training, 2025* (2025, cited 1x). Used for: background context. Role(s): General reference. Sections: \olmothreebase > Stage 1: Pretraining > Sampling and Mixing over Data Pools > Constrained data mixing Files: section-3-base-kyle.tex
- `ding2023enhancing` — *Enhancing chat language models by scaling high-quality instructional conversations* (2023, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Evaluation Details > New Evaluation Benchmarks > Masked perplexity; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `ding2024fewertruncationsimprovelanguage` — *Fewer truncations improve language modeling, 2024* (2024, cited 1x). Used for: long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Long-context / document understanding. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > Document packing Files: LC-luca-YOUMAYTOUCH.tex
- `drtulu` — *DR Tulu: Reinforcement learning with evolving rubrics for deep research, 2025a* (2025a, cited 2x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context; post-training (SFT/DPO/RL*) method or dataset; training stack / distributed systems / efficiency tooling. Role(s): Evaluation benchmark / methodology, Tool use / function calling, Post-training / alignment / RL, Infrastructure / systems. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Evaluating function calling; \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `dua-etal-2019-drop` — *DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs* (2019, cited 3x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Long-context / document understanding. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `dubey2024llama` — *The llama 3 herd of models, 2024* (2024, cited 3x). Used for: external baseline model and/or public recipe reference; architecture/optimization component referenced or adapted; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Open-weight model / baseline, Architecture / optimization component, Long-context / document understanding. Sections: Introduction; Stage 3: Long-context Extension > Curating a Training Recipe for Extension > Intra-document masking; Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex, section-1-intro-hanna2.tex
- `dubois2024length` — *Length-controlled alpacaeval: A simple way to debias automatic evaluators* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Safety / risk. Sections: Post-Training Additional Evaluation Details > General Evaluation Settings Files: section8-appendix-posttrain.tex, tables/posttrain/eval_config_posttrain.tex
- `evalplus` — *Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation* (2023b, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `fan2019eli5` — *Eli5: Long form question answering* (2019, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification Files: section-3-base-kyle.tex
- `fang2025datasetsdocumentsrepetitionspracticalities` — *Datasets, documents, and repetitions: The practicalities of unequal data quality, 2025a* (2025a, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Deduplication Files: section-3-base-kyle.tex
- `fang2025wrongperplexitylongcontextlanguage` — *What is wrong with perplexity for long-context language modeling?, 2025b* (2025b, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Scaling laws / compute framing, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Sourcing Long Context Data > Data filtering Files: LC-luca-YOUMAYTOUCH.tex
- `Fleming2017-FLESOD` — *Self-evaluation of decision-making: A general bayesian framework for metacognitive computation* (2017, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `fujii2025rewriting` — *Rewriting pre-training data boosts llm performance in math and code* (2025, cited 4x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Code Capabilities; Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > CraneMath; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Code capabilities; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Math capabilities Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `gandhi2025cognitive` — *Cognitive behaviors that enable self-improving reasoners, or, four habits of highly effective stars* (2025, cited 3x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces; \olmothreerlzero > Key Findings > \olmothreerlzero can benchmark reasoning data mixes in midtraining Files: section-3-base-kyle.tex, section-6-rlzero.tex, section8-appendix-base.tex
- `gao2020pile` — *The pile: An 800gb dataset of diverse text for language modeling* (2020, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto). Role(s): Data / preprocessing / filtering, Scaling laws / compute framing. Sections: \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex
- `gemma` — *Gemma: Open models based on gemini research and technology* (2024, cited 1x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics Files: section8-appendix-posttrain.tex
- `geng2025delta` — *The delta learning hypothesis: Preference tuning on weak data can yield strong gains* (2025, cited 10x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Reasoning / thinking, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Post-training; \olmothreeinstruct > Key Findings > High contrast in preference pairs drives DPO improvements; \olmothreeinstruct > Key Findings > The ideal amount of preference data depends on the downstream task; \olmothreeinstruct > Preference Tuning with \dolciinstructdpo > Preference Signals > Delta-learning heuristic pairs; \olmothreeinstruct > Preference Tuning with \dolciinstructdpo > Preference Signals > Multi-turn preferences; \olmothreethinking > Preference Tuning with Delta Learning; +3 more Files: section-2-ake.tex, section-4-think.tex, section-5-instruct-pradeep.tex
- `glm45` — *GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, 2025* (2025, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Safety / risk. Sections: Stage 3: Long-context Extension > High variance in open-model recipes; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details Files: LC-luca-YOUMAYTOUCH.tex, section-4-think.tex
- `goddard-etal-2024-arcees` — *Arcee's MergeKit: A toolkit for merging large language models* (2024, cited 1x). Used for: architecture/optimization component referenced or adapted; benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context; post-training (SFT/DPO/RL*) method or dataset. Role(s): Architecture / optimization component, Evaluation benchmark / methodology, Reasoning / thinking, Tool use / function calling, Post-training / alignment / RL. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > Training Files: section-4-think.tex
- `goddard2025extendingAFM` — *Extending AFM-4.5B to 64K context length* (2025, cited 1x). Used for: long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Long-context / document understanding. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `godey2025gaperonpepperedenglishfrenchgenerative` — *Gaperon: A peppered english-french generative language model suite, 2025* (2025, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreebase > Stage 2: Midtraining > Decontamination Files: section-3-base-kyle.tex
- `google-gemini2.5` — *Gemini 2.5: Our most intelligent ai model* (2025, cited 1x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview Files: section8-appendix-posttrain.tex
- `gpt35` — *GPT-3.5 turbo, 2023a* (2023a, cited 1x). Used for: external baseline model and/or public recipe reference; tokenizer/vocabulary design context; benchmark definition or evaluation methodology. Role(s): Open-weight model / baseline, Tokenizer / vocabulary, Evaluation benchmark / methodology. Sections: \olmothreebase > Modeling and Architecture > Tokenizer Files: section-3-base-kyle.tex
- `gpt4` — *GPT-4 technical report* (2023b, cited 3x). Used for: external baseline model and/or public recipe reference; tokenizer/vocabulary design context; benchmark definition or evaluation methodology. Role(s): Open-weight model / baseline, Tokenizer / vocabulary, Evaluation benchmark / methodology. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; Post-Training Additional Evaluation Details > General Evaluation Settings; \olmothreebase > Modeling and Architecture > Tokenizer Files: section-3-base-kyle.tex, section8-appendix-posttrain.tex
- `GRIFFITHS201924` — *Doing more with less: meta-reasoning and meta-learning in humans and machines* (2019, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `gsm-symbolic` — *Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models, 2024* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/base_eval/eval_config.tex
- `gu2024cruxeval` — *Cruxeval: A benchmark for code reasoning, understanding and execution* (2024a, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; training stack / distributed systems / efficiency tooling. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Infrastructure / systems. Sections: \olmothreebase > Experimental Design and Evaluation > Signal-to-Noise Analysis Files: section-3-base-kyle.tex
- `guha2025openthoughts` — *Openthoughts: Data recipes for reasoning models* (2025a, cited 9x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Scaling laws / compute framing, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking; \olmothreethinking > Preference Tuning with Delta Learning; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `guha2025openthoughtsdatarecipesreasoning` — *Openthoughts: Data recipes for reasoning models, 2025b* (2025b, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Existing thinking traces Files: section8-appendix-base.tex
- `guo2024deepseek` — *Deepseek-coder: When the large language model meets programming--the rise of code intelligence* (2024, cited 2x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Evaluation Details > Expanding OLMES tasks Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex
- `guo2025deepseek` — *Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning* (2025, cited 3x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Reasoning / thinking, Safety / risk. Sections: Post-Training Additional Evaluation Details > General Evaluation Settings; \olmothreerlzero; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, section-6-rlzero.tex, section8-appendix-posttrain.tex
- `han2024wildguard` — *Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms* (2024, cited 8x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; tool-use or function-calling interface/eval context; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Data / preprocessing / filtering, Tool use / function calling, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `Haupt2018` — *Hierarchical thinking: a cognitive tool for guiding coherent decision making in design problem solving* (2018, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Tool use / function calling. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `heineman2025signalnoiseframeworkreducing` — *Signal and noise: A framework for reducing uncertainty in language model evaluation, 2025* (2025, cited 2x). Used for: architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; post-training (SFT/DPO/RL*) method or dataset. Role(s): Architecture / optimization component, Scaling laws / compute framing, Evaluation benchmark / methodology, Post-training / alignment / RL. Sections: \olmothreebase > Experimental Design and Evaluation; \olmothreebase > Experimental Design and Evaluation > Signal-to-Noise Analysis Files: section-3-base-kyle.tex
- `hendrycksapps2021` — *Measuring coding challenge competence with apps* (2021a, cited 2x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `hendrycksmath2021` — *Measuring mathematical problem solving with the math dataset* (2021c, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > TinyMATH Files: section8-appendix-base.tex
- `hendryckstest2021` — *Measuring massive multitask language understanding* (2021b, cited 6x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex, tables/posttrain/eval_config_posttrain.tex
- `horgan2018distributed` — *Distributed prioritized experience replay* (2018, cited 1x). Used for: training stack / distributed systems / efficiency tooling. Role(s): Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Fully asynchronous training Files: section-4-think.tex
- `hsieh2024rulerwhatsrealcontext` — *Ruler: What's the real context size of your long-context language models?, 2024* (2024, cited 3x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Long-context / document understanding. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Long-Context suite; Stage 3: Long-context Extension > Overall results Files: LC-luca-YOUMAYTOUCH.tex, section8-appendix-base.tex
- `hsu2025ligerkernelefficienttriton` — *Liger kernel: Efficient triton kernels for llm training, 2025* (2025, cited 1x). Used for: architecture/optimization component referenced or adapted; post-training (SFT/DPO/RL*) method or dataset. Role(s): Architecture / optimization component, Post-training / alignment / RL. Sections: \olmothreebase > Modeling and Architecture > Training Files: section-3-base-kyle.tex
- `hu2025open` — *Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model* (2025, cited 3x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Data; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, section-6-rlzero.tex, tables/posttrain_data/rlvr_data.tex
- `huang2024compression` — *Compression represents intelligence linearly* (2024b, cited 2x). Used for: tool-use or function-calling interface/eval context. Role(s): Tool use / function calling. Sections: Appendix > Base Model Additional Evaluation Details > Expanding OLMES tasks; \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `huang2024trustllm` — *Trustllm: Trustworthiness in large language models* (2024a, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex
- `jain2024livecodebench` — *Livecodebench: Holistic and contamination free evaluation of large language models for code* (2024, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `jiang2022moreparameterfreetextclassification` — *Less is more: Parameter-free text classification with gzip, 2022* (2022, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto). Role(s): Scaling laws / compute framing. Sections: Stage 3: Long-context Extension > Sourcing Long Context Data > Data filtering Files: LC-luca-YOUMAYTOUCH.tex
- `jiang2024wildteaming` — *Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models* (2024, cited 5x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `jin2021disease` — *What disease does this patient have? a large-scale open domain question answering dataset from medical exams* (2021, cited 2x). Used for: background context. Role(s): General reference. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Joyce2009` — *Causal reasoning and backtracking* (2009, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex
- `k2team2025k2v2360openreasoningenhancedllm` — *K2-v2: A 360-open, reasoning-enhanced llm, 2025* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Introduction Files: section-1-intro-hanna2.tex
- `kaiyom2024helmsafety` — *HELM safety: Towards standardized safety evaluations of language models, 8 Nov. 2024* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics Files: section8-appendix-posttrain.tex
- `kargupta2025cognitive` — *Cognitive foundations for reasoning and their manifestation in llms* (2025, cited 2x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex
- `kim2023aligning` — *Aligning large language models through synthetic feedback* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Data / preprocessing / filtering, Reasoning / thinking. Sections: \olmothreethinking > Preference Tuning with Delta Learning > \dolcithink-DPO: Preference Data Creation > Step 1: sourcing prompts and contrastive completions Files: section-4-think.tex
- `kim2025systematic` — *A systematic examination of preference learning through the lens of instruction-following* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Preference Tuning with Delta Learning > Delta Learning Files: section-4-think.tex
- `kimiK2` — *Kimi k2: Open agentic intelligence, 2025* (2025, cited 1x). Used for: background context. Role(s): General reference. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `kopf2024openassistant` — *Openassistant conversations-democratizing large language model alignment* (2024, cited 4x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Data / preprocessing / filtering, Reasoning / thinking, Long-context / document understanding, Safety / risk. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `kudugunta2023madlad400multilingualdocumentlevellarge` — *Madlad-400: A multilingual and document-level large audited dataset, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl Files: section8-appendix-base.tex
- `kwiatkowski-etal-2019-natural` — *Natural questions: A benchmark for question answering research* (2019, cited 3x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Lai2022DS1000` — *Ds-1000: A natural and reliable benchmark for data science code generation* (2022, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/eval_config.tex
- `lambert2023entangled` — *Entangled preferences: The history and risks of reinforcement learning and human feedback* (2023, cited 1x). Used for: post-training (SFT/DPO/RL*) method or dataset; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Post-training / alignment / RL, Safety / risk. Files: tables/posttrain_data/think_dpo_mix.tex
- `lambert2024tulu3` — *Tulu 3: Pushing frontiers in open language model post-training* (2024, cited 21x). Used for: benchmark definition or evaluation methodology; post-training (SFT/DPO/RL*) method or dataset; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Post-training / alignment / RL, Safety / risk. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; Post-Training Additional Evaluation Details > Safety Evaluations Overview; Post-Training Additional Training Details > Preference Tuning Details > Training Settings; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-Capability instruction data; \olmothreethinking; \olmothreethinking > Preference Tuning with Delta Learning; +4 more Files: section-3-base-kyle.tex, section-4-think.tex, section8-appendix-posttrain.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/rlvr_data.tex, tables/posttrain_data/think_dpo_mix.tex
- `laurent2024lab` — *Lab-bench: Measuring capabilities of language models for biology research* (2024, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex
- `lee2022deduplicatingtrainingdatamakes` — *Deduplicating training data makes language models better, 2022* (2022, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; tokenizer/vocabulary design context; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Tokenizer / vocabulary, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > Deduplication > MinHash~Fuzzy deduplication; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Deduplication Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `lewkowycz2022solving` — *Solving quantitative reasoning problems with language models* (2022, cited 6x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Easy suite Files: section8-appendix-base.tex, tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex, tables/posttrain/eval_config_posttrain.tex
- `li2024crowdsourced` — *From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline* (2024c, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: Post-Training Additional Evaluation Details > General Evaluation Settings > Is AlpacaEval useful? Files: section8-appendix-posttrain.tex
- `lightman2023lets` — *Let's verify step by step* (2023, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/base_eval/eval_config.tex, tables/posttrain/eval_config_posttrain.tex
- `lin2025zebralogic` — *Zebralogic: On the scaling limits of llms for logical reasoning* (2025, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context. Role(s): Scaling laws / compute framing, Reasoning / thinking, Tool use / function calling. Files: tables/posttrain/eval_config_posttrain.tex
- `liu2023llm360` — *Llm360: Towards fully transparent open-source llms* (2023c, cited 1x). Used for: fully-open precedent (release of weights+data+code) or open-data pipeline reference; dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > MegaMatt Files: section8-appendix-base.tex
- `liu2023tinygsmachieving80gsm8k` — *Tinygsm: achieving >80% on gsm8k with small language models, 2023a* (2023a, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > TinyMATH Files: section8-appendix-base.tex
- `Liu2024APIGenAP` — *Apigen: Automated pipeline for generating verifiable and diverse function-calling datasets* (2024c, cited 1x). Used for: tool-use or function-calling interface/eval context. Role(s): Tool use / function calling. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with simulated interactions Files: section-5-instruct-pradeep.tex
- `liu2024regmix` — *Regmix: Data mixture as regression for language model pre-training* (2024a, cited 1x). Used for: background context. Role(s): General reference. Sections: \olmothreebase > Stage 1: Pretraining > Sampling and Mixing over Data Pools > Constrained data mixing Files: section-3-base-kyle.tex
- `Liu2024ToolACEWT` — *Toolace: Winning the points of llm function calling* (2024b, cited 1x). Used for: tool-use or function-calling interface/eval context. Role(s): Tool use / function calling. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with simulated interactions Files: section-5-instruct-pradeep.tex
- `liu2025prorl` — *Prorl: Prolonged reinforcement learning expands reasoning boundaries in large language models* (2025a, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreerlzero Files: section-6-rlzero.tex
- `liu2025understanding` — *Understanding r1-zero-like training: A critical perspective* (2025b, cited 6x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Post-training; \olmothreerlzero; \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Prompt and eval template; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details Files: section-2-ake.tex, section-4-think.tex, section-6-rlzero.tex
- `longbench1` — *LongBench: A bilingual, multitask benchmark for long context understanding* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Experiments with Synthetic Augmentation Files: LC-luca-YOUMAYTOUCH.tex
- `longbench2` — *LongBench v2: Towards deeper understanding and reasoning on realistic long-context multitasks* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Reasoning / thinking, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Experiments with Synthetic Augmentation Files: LC-luca-YOUMAYTOUCH.tex
- `longpre2023flan` — *The flan collection: Designing data and methods for effective instruction tuning* (2023, cited 1x). Used for: background context. Role(s): General reference. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-Capability instruction data Files: section-3-base-kyle.tex
- `lozhkov2024starcoder` — *Starcoder 2 and the stack v2: The next generation* (2024, cited 4x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines; training stack / distributed systems / efficiency tooling. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Long-context / document understanding, Infrastructure / systems. Sections: Appendix > Base Model Additional Data Details: Midtraining > Code Capabilities > CraneCode; \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Code; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Code capabilities Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `luo2023wizardcoder` — *Wizardcoder: Empowering code large language models with evol-instruct, 2023* (2023, cited 2x). Used for: safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Safety / risk. Files: tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `luo2025deepscaler` — *Deepscaler: Surpassing o1-preview with a 1.5 b model by scaling rl* (2025b, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreerlzero; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, section-6-rlzero.tex
- `Magar2022DataCF` — *Data contamination: From memorization to exploitation* (2022, cited 1x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreebase > Stage 2: Midtraining > Decontamination Files: section-3-base-kyle.tex
- `magnusson2024palomabenchmarkevaluatinglanguage` — *Paloma: A benchmark for evaluating language model fit, 2024* (2024, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: \olmothreebase > Stage 2: Midtraining > Decontamination Files: section-3-base-kyle.tex
- `magnusson2025datadecidepredictbestpretraining` — *Datadecide: How to predict best pretraining data with small experiments, 2025* (2025, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreebase > Experimental Design and Evaluation; \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex
- `mallen2023llm_memorization` — *When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories* (2022, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `marjanović2025deepseekr1thoughtologyletsthink` — *Deepseek-r1 thoughtology: Let's think about llm reasoning, 2025* (2025, cited 1x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Open-weight model / baseline, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreerlzero Files: section-6-rlzero.tex
- `Markovits2015` — *Metacognition and abstract reasoning* (2015, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `matton-etal-2024-leakage` — *On leakage of code generation evaluation datasets* (2024, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Held-out Suite Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex
- `mazeika2024harmbench` — *Harmbench: A standardized evaluation framework for automated red teaming and robust refusal* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Evaluation benchmark / methodology, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex
- `mimo` — *MiMo: Unlocking the reasoning potential of language model -- from pretraining to posttraining, 2025* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Long-context / document understanding, Post-training / alignment / RL. Sections: Stage 3: Long-context Extension > Overall results Files: LC-luca-YOUMAYTOUCH.tex
- `mindermann2022prioritized` — *Prioritized training on points that are learnable, worth learning, and not yet learnt* (2022, cited 1x). Used for: training stack / distributed systems / efficiency tooling. Role(s): Infrastructure / systems. Sections: Appendix > Base Model Additional Evaluation Details > New Evaluation Benchmarks > Masked perplexity Files: section8-appendix-base.tex
- `Miroyan2025SearchAA` — *Search arena: Analyzing search-augmented llms* (2025, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `modelmerginginpretraining` — *Model merging in pre-training of large language models* (2025, cited 1x). Used for: architecture/optimization component referenced or adapted. Role(s): Architecture / optimization component. Sections: \olmothreebase > Stage 1: Pretraining > Sampling and Mixing over Data Pools > Evaluation during pretraining Files: section-3-base-kyle.tex
- `morrison2024mergelearnefficientlyadding` — *Merge to learn: Efficiently adding skills to language models with model merging, 2024* (2024, cited 1x). Used for: architecture/optimization component referenced or adapted; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Architecture / optimization component, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > Training Files: section-4-think.tex
- `mosaic-jeopardy` — *Llm foundry - jeopardy dataset* (2024, cited 3x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `moshkov2025aimo2` — *AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset* (2025, cited 5x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Data / preprocessing / filtering, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > OMR Rewrites; Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Existing thinking traces; Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `muennighoff2025s1simpletesttimescaling` — *s1: Simple test-time scaling, 2025b* (2025b, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Existing thinking traces; Stage 3: Long-context Extension Files: LC-luca-YOUMAYTOUCH.tex, section8-appendix-base.tex
- `muennighoff2025scalingdataconstrainedlanguagemodels` — *Scaling data-constrained language models, 2025a* (2025a, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Deduplication Files: section-3-base-kyle.tex
- `nelson2024needlehaystackmemorybased` — *Needle in the haystack for memory based large language models, 2024* (2024, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Overall results Files: LC-luca-YOUMAYTOUCH.tex
- `NemotronPostTrainingDatasetV1` — *Nemotron-Post-Training-Dataset-v1, 2025* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Post-Training Additional Data Details > Filtering for \dolcithink-SFT Files: section8-appendix-posttrain.tex
- `noukhovitch2024asynchronousrlhffasterefficient` — *Asynchronous rlhf: Faster and more efficient off-policy rl for language models, 2024* (2024, cited 2x). Used for: post-training (SFT/DPO/RL*) method or dataset; training stack / distributed systems / efficiency tooling. Role(s): Post-training / alignment / RL, Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Fully asynchronous training Files: section-4-think.tex
- `nvidia/Nemotron-Personas-USA` — *Nemotron-Personas-USA: Synthetic personas aligned to real-world distributions, June 2025* (2025, cited 1x). Used for: external baseline model and/or public recipe reference. Role(s): Open-weight model / baseline. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex
- `nvidia2025nemotron_post_training_dataset` — *Nemotron-post-training-dataset-v1* (2025, cited 4x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: Post-Training Additional Data Details > Coding Data Synthesis Pipeline; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, section8-appendix-posttrain.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/rlvr_data.tex
- `nvidia2025nvidianemotronnano2` — *NVIDIA Nemotron Nano 2: An accurate and efficient hybrid mamba-transformer reasoning model, 2025* (2025, cited 1x). Used for: external baseline model and/or public recipe reference; architecture/optimization component referenced or adapted; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Architecture / optimization component, Reasoning / thinking. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `Olieslagers2024` — *Backward reasoning through and/or trees to solve problems* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `olmes` — *Olmes: A standard for language model evaluations* (2024b, cited 4x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Evaluation Details; \olmothreebase > Experimental Design and Evaluation Files: section-3-base-kyle.tex, section8-appendix-base.tex, tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `olmix` — *Olmix: Efficient mixture recomputation for evolving lm datasets, 2026* (2026, cited 3x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl Mixing; \olmothreebase > Stage 1: Pretraining > Sampling and Mixing over Data Pools > Constrained data mixing Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `olmo20242olmo2furious` — *2 olmo 2 furious, 2024* (2024, cited 13x). Used for: fully-open precedent (release of weights+data+code) or open-data pipeline reference; dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Reasoning / thinking, Tool use / function calling. Sections: Appendix > Base Model Additional Evaluation Details; Model Flow for \olmothree; Model Flow for \olmothree > Base Model Training > Data curriculum; Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; Post-Training Additional Evaluation Details > Safety Evaluations Overview; \olmothreebase > Stage 1: Pretraining; +4 more Files: section-2-ake.tex, section-3-base-kyle.tex, section-4-think.tex, section8-appendix-base.tex, section8-appendix-posttrain.tex, tables/base_eval/easy_eval_config.tex, +2 more
- `openai-gpt5-systemcard` — *Gpt-5 system card* (2025, cited 1x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview Files: section8-appendix-posttrain.tex
- `OpenHermes` — *Openhermes 2.5: An open dataset of synthetic data for generalist llm assistants, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification Files: section-3-base-kyle.tex
- `pandey2024gzippredictsdatadependentscaling` — *gzip predicts data-dependent scaling laws, 2024* (2024, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto). Role(s): Scaling laws / compute framing. Sections: Stage 3: Long-context Extension > Sourcing Long Context Data > Data filtering Files: LC-luca-YOUMAYTOUCH.tex
- `paperno2016lambada` — *The lambada dataset: Word prediction requiring a broad discourse context* (2016, cited 2x). Used for: background context. Role(s): General reference. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `parrish-etal-2022-bbq` — *BBQ: A hand-built bias benchmark for question answering* (2022, cited 3x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Unseen safety evaluations Files: section8-appendix-posttrain.tex
- `paster2023openwebmath` — *Openwebmath: An open dataset of high-quality mathematical web text, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; architecture/optimization component referenced or adapted; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Architecture / optimization component, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Math Files: section-3-base-kyle.tex
- `patil2025bfcl` — *The berkeley function calling leaderboard (bfcl): From tool use to agentic evaluation of large language models* (2025, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Tool use / function calling. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Evaluating function calling Files: section-5-instruct-pradeep.tex, tables/posttrain/eval_config_posttrain.tex
- `penedo2023refinedwebdatasetfalconllm` — *The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl Files: section8-appendix-base.tex
- `penedo2024fineweb` — *The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale* (2024, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Pretraining > CommonCrawl; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool > Deduplication Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `peng2023yarnefficientcontextwindow` — *Yarn: Efficient context window extension of large language models, 2023* (2023, cited 2x). Used for: architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Architecture / optimization component, Scaling laws / compute framing, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > RoPE extension; Stage 3: Long-context Extension > \olmothree long-context recipe Files: LC-luca-YOUMAYTOUCH.tex
- `peS2o` — *peS2o (Pretraining Efficiently on S2ORC) Dataset, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool Files: section-3-base-kyle.tex
- `pham2025clipper` — *Clipper: Compression enables long-context synthetic data generation, 2025* (2025, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Experiments with Synthetic Augmentation Files: LC-luca-YOUMAYTOUCH.tex
- `pipelinerl` — *Pipelinerl: Faster on-policy reinforcement learning for long sequence generatio* (2025, cited 2x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Inflight updates Files: section-4-think.tex
- `pmlr-v174-pal22a` — *Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering* (2022, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Polaris2025` — *Polaris: A post-training recipe for scaling reinforcement learning on advanced reasoning models, 2025* (2025, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Reasoning / thinking. Files: tables/posttrain_data/rlvr_data.tex
- `poznanski2025olmocr` — *olmOCR: Unlocking trillions of tokens in pdfs with vision language models* (2025a, cited 5x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; tokenizer/vocabulary design context; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Tokenizer / vocabulary, Long-context / document understanding. Sections: Model Flow for \olmothree > Base Model Training > Data curriculum; \olmothreebase > Stage 1: Pretraining; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool > PII filtering; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool > \olmOCR text extraction Files: section-2-ake.tex, section-3-base-kyle.tex
- `poznanski2025olmocr2unittest` — *olmOCR 2: Unit Test Rewards for Document OCR, 2025b* (2025b, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Long-context / document understanding, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Base Model Training > Data curriculum Files: section-2-ake.tex
- `primeintellect2025synthetic2` — *Synthetic-2* (2025, cited 8x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Scaling laws / compute framing, Reasoning / thinking, Post-training / alignment / RL. Sections: Post-Training Additional Data Details > Coding Data Synthesis Pipeline; \olmothreethinking; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details > Verifiers; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, section8-appendix-posttrain.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/rlvr_data.tex
- `prolong` — *How to train long-context language models (effectively)* (2025, cited 1x). Used for: architecture/optimization component referenced or adapted; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Architecture / optimization component, Long-context / document understanding. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `pyatkin2025generalizing` — *Generalizing verifiable instruction following* (2025, cited 4x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, tables/posttrain_data/rlvr_data.tex
- `qwen1M` — *Qwen2.5-1M Technical Report, 2025b* (2025b, cited 1x). Used for: external baseline model and/or public recipe reference; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Open-weight model / baseline, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Experiments with Synthetic Augmentation Files: LC-luca-YOUMAYTOUCH.tex
- `qwen2.5` — *Qwen2.5 technical report, 2024* (2024, cited 3x). Used for: external baseline model and/or public recipe reference; dataset, data-mix ingredient, or data-processing/filtering method; tool-use or function-calling interface/eval context. Role(s): Open-weight model / baseline, Data / preprocessing / filtering, Tool use / function calling. Sections: Appendix > Base Model Additional Data Details: Midtraining > Code Capabilities > CraneCode; Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Main suite; Introduction Files: section-1-intro-hanna2.tex, section8-appendix-base.tex
- `qwen3` — *Qwen3 technical report* (2025a, cited 11x). Used for: external baseline model and/or public recipe reference; compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Open-weight model / baseline, Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > CraneMath; Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Main suite; Introduction; Model Flow for \olmothree > Post-training; Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; Stage 3: Long-context Extension > Overall results; +3 more Files: LC-luca-YOUMAYTOUCH.tex, section-1-intro-hanna2.tex, section-2-ake.tex, section-3-base-kyle.tex, section-4-think.tex, section-6-rlzero.tex, +2 more
- `qwen_qwq_32b_2025` — *Qwq-32b: Embracing the power of reinforcement learning* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs Files: section8-appendix-posttrain.tex
- `rafailov2024direct` — *Direct preference optimization: Your language model is secretly a reward model* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Preference Tuning with Delta Learning Files: section-4-think.tex
- `rajpurkar-etal-2016-squad` — *SQuAD: 100,000+ questions for machine comprehension of text* (2016, cited 3x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `reddy-etal-2019-coqa` — *CoQA: A conversational question answering challenge* (2019, cited 3x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `rein2024gpqa` — *GPQA: A graduate-level google-proof q\&a benchmark* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `rlhf2024` — *Reinforcement Learning from Human Feedback* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Preference Tuning with Delta Learning Files: section-4-think.tex
- `rottger2023xstest` — *Xstest: A test suite for identifying exaggerated safety behaviours in large language models* (2023, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Evaluation benchmark / methodology, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex
- `rozière2024codellamaopenfoundation` — *Code llama: Open foundation models for code, 2024* (2024, cited 1x). Used for: external baseline model and/or public recipe reference; architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Open-weight model / baseline, Architecture / optimization component, Scaling laws / compute framing, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > RoPE extension Files: LC-luca-YOUMAYTOUCH.tex
- `Sakaguchi_Le_Bras_Bhagavatula_Choi_2020` — *WinoGrande: An adversarial winograd schema challenge at scale* (2020, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `sap-etal-2019-social` — *Social IQa: Commonsense reasoning about social interactions* (2019, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `saxton2019analysing` — *Analysing mathematical reasoning abilities of neural models* (2019, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Held-out Suite Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex
- `scalingllama3` — *Scaling llama 3 training with efficient parallelism strategies* (2025, cited 4x). Used for: external baseline model and/or public recipe reference; architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines; post-training (SFT/DPO/RL*) method or dataset. Role(s): Open-weight model / baseline, Architecture / optimization component, Scaling laws / compute framing, Evaluation benchmark / methodology, Long-context / document understanding, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Post-training; Stage 3: Long-context Extension > Curating a Training Recipe for Extension > LC training infrastructure; \olmothreerlzero Files: LC-luca-YOUMAYTOUCH.tex, section-2-ake.tex, section-6-rlzero.tex, tables/base_training/training_config.tex
- `schaeffer2023emergent` — *Are emergent abilities of large language models a mirage?* (2023, cited 1x). Used for: long-context training/eval, document understanding, or OCR/PDF pipelines; tool-use or function-calling interface/eval context. Role(s): Long-context / document understanding, Tool use / function calling. Sections: \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex
- `shao2024deepseekmath` — *Deepseekmath: Pushing the limits of mathematical reasoning in open language models* (2024, cited 2x). Used for: external baseline model and/or public recipe reference; benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Open-weight model / baseline, Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Key Findings > DPO and SFT both benefit from RL, but DPO remains a better starting point; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details Files: section-4-think.tex
- `shao2025spuriousrewardsrethinkingtraining` — *Spurious rewards: Rethinking training signals in rlvr, 2025b* (2025b, cited 4x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Post-training; \olmothreerlzero; \olmothreerlzero > Key Findings > Eval decontamination is verified via spurious rewards Files: section-2-ake.tex, section-6-rlzero.tex
- `shen2024anything` — *" do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models* (2024, cited 2x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Development safety evaluations Files: section8-appendix-posttrain.tex
- `Shi2025TaskCraftAG` — *Taskcraft: Automated generation of agentic tasks* (2025, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `silver2017alphazero` — *Mastering chess and shogi by self-play with a general reinforcement learning algorithm* (2017, cited 1x). Used for: training stack / distributed systems / efficiency tooling. Role(s): Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Fully asynchronous training Files: section-4-think.tex
- `singh2024aya` — *Aya dataset: An open-access collection for multilingual instruction tuning* (2024, cited 4x). Used for: background context. Role(s): General reference. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `skarlinski2024language` — *Language agents achieve superhuman synthesis of scientific knowledge* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Evaluating function calling Files: section-5-instruct-pradeep.tex, tables/posttrain/eval_config_posttrain.tex
- `soldaini2024dolma` — *Dolma: an open corpus of three trillion tokens for language model pretraining research, 2024* (2024, cited 3x). Used for: fully-open precedent (release of weights+data+code) or open-data pipeline reference; dataset, data-mix ingredient, or data-processing/filtering method; tokenizer/vocabulary design context; benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Tokenizer / vocabulary, Evaluation benchmark / methodology, Tool use / function calling. Sections: Model Flow for \olmothree > Base Model Training > Data curriculum; \olmothreebase > Stage 1: Pretraining; \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Other Files: section-2-ake.tex, section-3-base-kyle.tex
- `souleBergmann2025granite33` — *IBM Granite 3.3: Speech recognition, refined reasoning, and RAG LoRAs, Apr. 2025* (2025, cited 1x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Open-weight model / baseline, Reasoning / thinking, Long-context / document understanding. Sections: Introduction Files: section-1-intro-hanna2.tex
- `stiennon2020learning` — *Learning to summarize with human feedback* (2020, cited 1x). Used for: benchmark definition or evaluation methodology; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Post-training / alignment / RL. Sections: \olmothreerlzero > Key Findings > \olmothreerlzero mix can benchmark challenges in multi-objective RL Files: section-6-rlzero.tex
- `strongreject` — *A strongreject for empty jailbreaks* (2024, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Unseen safety evaluations Files: section8-appendix-posttrain.tex
- `su2024roformer` — *Roformer: Enhanced transformer with rotary position embedding* (2024, cited 1x). Used for: architecture/optimization component referenced or adapted; benchmark definition or evaluation methodology. Role(s): Architecture / optimization component, Evaluation benchmark / methodology. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > RoPE extension Files: LC-luca-YOUMAYTOUCH.tex
- `su2025expanding` — *Expanding rl with verifiable rewards across diverse domains* (2025b, cited 2x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, tables/posttrain_data/rlvr_data.tex
- `su2025klear` — *Klear-reasoner: Advancing reasoning capability via gradient-preserving clipping policy optimization* (2025c, cited 6x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Data / preprocessing / filtering, Reasoning / thinking. Sections: Post-Training Additional Data Details > Coding Data Synthesis Pipeline; \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Data; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, section-6-rlzero.tex, section8-appendix-posttrain.tex, tables/posttrain_data/rlvr_data.tex
- `su2025nemotroncctransformingcommoncrawl` — *Nemotron-cc: Transforming common crawl into a refined long-horizon pretraining dataset, 2025a* (2025a, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > QA and knowledge access capabilities Files: section-3-base-kyle.tex
- `Sun2025OMEGACL` — *Omega: Can llms reason outside the box in math? evaluating exploratory, compositional, and transformative generalization* (2025, cited 4x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work. Role(s): Data / preprocessing / filtering, Reasoning / thinking. Sections: \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Data; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, section-6-rlzero.tex, tables/posttrain/eval_config_posttrain.tex, tables/posttrain_data/rlvr_data.tex
- `suzgun2022challenging` — *Challenging big-bench tasks and whether chain-of-thought can solve them* (2022, cited 3x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Tool use / function calling. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Held-out Suite Files: section8-appendix-base.tex, tables/base_eval/eval_config.tex, tables/posttrain/eval_config_posttrain.tex
- `swissai2025apertus` — *Apertus: Democratizing Open and Compliant LLMs for Global Language Environments* (2025, cited 2x). Used for: fully-open precedent (release of weights+data+code) or open-data pipeline reference; dataset, data-mix ingredient, or data-processing/filtering method; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Fully open model / precedent, Data / preprocessing / filtering, Reasoning / thinking, Long-context / document understanding. Sections: Introduction; Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex, section-1-intro-hanna2.tex
- `tacoli` — *Taco: Topics in algorithmic code generation dataset* (2023a, cited 2x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `talmor-etal-2019-commonsenseqa` — *CommonsenseQA: A question answering challenge targeting commonsense knowledge* (2019, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `team2025gemma3` — *Gemma 3 technical report, 2025* (2025, cited 4x). Used for: external baseline model and/or public recipe reference; compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Open-weight model / baseline, Scaling laws / compute framing, Reasoning / thinking, Long-context / document understanding. Sections: Introduction; Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs; Stage 3: Long-context Extension > Sourcing Long Context Data > Data filtering; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool > PII filtering Files: LC-luca-YOUMAYTOUCH.tex, section-1-intro-hanna2.tex, section-3-base-kyle.tex, section8-appendix-posttrain.tex
- `thealgorithms_python` — *The algorithms -- python* (2025, cited 1x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex
- `together2023redpajama` — *RedPajama: An open source recipe to reproduce LLaMA training dataset, 2023* (2023, cited 1x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Data / preprocessing / filtering, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Math Files: section-3-base-kyle.tex
- `toshniwal2024openmathinstruct` — *Openmathinstruct-2: Accelerating ai for math with massive open-source instruction data* (2024, cited 2x). Used for: background context. Role(s): General reference. Files: tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `toxigen` — *Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection* (2022, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation; training stack / distributed systems / efficiency tooling. Role(s): Evaluation benchmark / methodology, Safety / risk, Infrastructure / systems. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Unseen safety evaluations Files: section8-appendix-posttrain.tex
- `toy2024metacognitionneedusingintrospection` — *Metacognition is all you need? using introspection in generative agents to improve goal-directed behavior, 2024* (2024, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Data Details: Midtraining > Thinking Capabilities > Meta-reasoning; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `vaswani2017attention` — *Attention is all you need* (2017, cited 1x). Used for: architecture/optimization component referenced or adapted; benchmark definition or evaluation methodology. Role(s): Architecture / optimization component, Evaluation benchmark / methodology. Sections: \olmothreebase > Modeling and Architecture > Architecture Files: section-3-base-kyle.tex
- `vaswani2025rnj1` — *Announcing rnj-1: Building instruments of intelligence, Dec. 2025* (2025, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreeinstruct > Main Results for \olmothreeinstruct Files: section-5-instruct-pradeep.tex
- `vendrow2025large` — *Do large language model benchmarks test reliability?* (2025, cited 1x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Tool use / function calling. Sections: \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex
- `vllm` — *Efficient memory management for large language model serving with pagedattention* (2023, cited 2x). Used for: architecture/optimization component referenced or adapted; reasoning / chain-of-thought / thinking-model related work; training stack / distributed systems / efficiency tooling. Role(s): Architecture / optimization component, Reasoning / thinking, Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details > Verifiers; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Infrastructure in \openinstruct > Fully asynchronous training Files: section-4-think.tex
- `wadden2024sciriff` — *Sciriff: A resource to enhance language model instruction-following over scientific literature* (2024, cited 3x). Used for: safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Safety / risk. Files: tables/base_eval/easy_eval_config.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `wang2024helpsteer2` — *Helpsteer2: Open-source dataset for training top-performing reward models* (2024b, cited 3x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: \olmothreethinking > Preference Tuning with Delta Learning > \dolcithink-DPO: Preference Data Creation > Step 1: sourcing prompts and contrastive completions Files: section-4-think.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `wang2024mmlu` — *Mmlu-pro: A more robust and challenging multi-task language understanding benchmark* (2024a, cited 3x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Held-out Suite; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics Files: section8-appendix-base.tex, section8-appendix-posttrain.tex, tables/base_eval/eval_config.tex
- `wang2025octothinker` — *Octothinker: Mid-training incentivizes reinforcement learning scaling* (2025, cited 2x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology, Reasoning / thinking, Long-context / document understanding. Sections: Appendix > Base Model Additional Data Details: Midtraining > Math Capabilities > MegaMatt; \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Math capabilities Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `ward1963hierarchical` — *Hierarchical grouping to optimize an objective function* (1963, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreebase > Experimental Design and Evaluation > Clustering Tasks Files: section-3-base-kyle.tex
- `weborganizer` — *Organize the web: Constructing domains enhances pre-training data curation, 2025* (2025, cited 5x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; long-context training/eval, document understanding, or OCR/PDF pipelines; tool-use or function-calling interface/eval context. Role(s): Data / preprocessing / filtering, Long-context / document understanding, Tool use / function calling. Sections: Appendix > Base Model Additional Data Details: Pretraining > Topic Classification; Stage 3: Long-context Extension > Sourcing Long Context Data > Data filtering; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification; \olmothreebase > Stage 1: Pretraining > Preparing our \olmocrPDF Data Pool > Heuristic filtering Files: LC-luca-YOUMAYTOUCH.tex, section-3-base-kyle.tex, section8-appendix-base.tex
- `wei2021flan` — *Finetuned language models are zero-shot learners* (2021, cited 3x). Used for: reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-Capability instruction data Files: section-3-base-kyle.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/think_dpo_mix.tex
- `wei2022emergent` — *Emergent abilities of large language models* (2022, cited 3x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); benchmark definition or evaluation methodology. Role(s): Scaling laws / compute framing, Evaluation benchmark / methodology. Sections: Appendix > Base Model Additional Evaluation Details > Expanding OLMES tasks; \olmothreebase > Experimental Design and Evaluation; \olmothreebase > Experimental Design and Evaluation > Scaling analysis Files: section-3-base-kyle.tex, section8-appendix-base.tex
- `wei2024measuring` — *Measuring short-form factuality in large language models* (2024, cited 2x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Evaluating function calling Files: section-5-instruct-pradeep.tex, tables/posttrain/eval_config_posttrain.tex
- `welbl-etal-2017-crowdsourcing` — *Crowdsourcing multiple choice science questions* (2017, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `Wikiextractor2015` — *Wikiextractor* (2015, cited 1x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Long-context / document understanding. Sections: \olmothreebase > Stage 1: Pretraining > Preparing Code, Math, and other sources > Other Files: section-3-base-kyle.tex
- `wmdp` — *The WMDP benchmark: Measuring and reducing malicious use with unlearning* (2024b, cited 2x). Used for: benchmark definition or evaluation methodology; safety evaluation, harms, jailbreaks, or risk mitigation. Role(s): Evaluation benchmark / methodology, Safety / risk. Sections: Post-Training Additional Evaluation Details > Safety Evaluations Overview > Averaging and reported metrics; Post-Training Additional Evaluation Details > Safety Evaluations Overview > Unseen safety evaluations Files: section8-appendix-posttrain.tex
- `wortsman2022model` — *Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time* (2022, cited 1x). Used for: architecture/optimization component referenced or adapted; reasoning / chain-of-thought / thinking-model related work; long-context training/eval, document understanding, or OCR/PDF pipelines; post-training (SFT/DPO/RL*) method or dataset. Role(s): Architecture / optimization component, Reasoning / thinking, Long-context / document understanding, Post-training / alignment / RL. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > Training Files: section-4-think.tex
- `wu-etal-2025-webwalker` — *WebWalker: Benchmarking LLMs in web traversal* (2025a, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `wu2025longattn` — *LongAttn: Selecting long-context training data via token-level attention, 2025b* (2025b, cited 1x). Used for: architecture/optimization component referenced or adapted; tokenizer/vocabulary design context; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Architecture / optimization component, Tokenizer / vocabulary, Long-context / document understanding. Sections: Stage 3: Long-context Extension > High variance in open-model recipes Files: LC-luca-YOUMAYTOUCH.tex
- `wu2025reasoning` — *Reasoning or memorization? unreliable results of reinforcement learning due to data contamination* (2025c, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: Model Flow for \olmothree > Post-training; \olmothreerlzero Files: section-2-ake.tex, section-6-rlzero.tex
- `xiong2023effectivelongcontextscalingfoundation` — *Effective long-context scaling of foundation models, 2023* (2023, cited 1x). Used for: architecture/optimization component referenced or adapted; compute/scaling framing (tokens, FLOPs, Pareto); long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Architecture / optimization component, Scaling laws / compute framing, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > RoPE extension Files: LC-luca-YOUMAYTOUCH.tex
- `Yang2018HotpotQAAD` — *Hotpotqa: A dataset for diverse, explainable multi-hop question answering* (2018, cited 1x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Function-calling Training Data > Trajectories with real interactions Files: section-5-instruct-pradeep.tex
- `yao2025offpolicy` — *Your efficient rl framework secretly brings you off-policy rl training, Aug. 2025* (2025, cited 3x). Used for: post-training (SFT/DPO/RL*) method or dataset; training stack / distributed systems / efficiency tooling. Role(s): Post-training / alignment / RL, Infrastructure / systems. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \olmothreerl Algorithmic Details > \olmothreerl formulation Files: section-4-think.tex
- `ye2025datamixinglawsoptimizing` — *Data mixing laws: Optimizing data mixtures by predicting language modeling performance, 2025* (2025, cited 1x). Used for: background context. Role(s): General reference. Sections: \olmothreebase > Stage 1: Pretraining > Sampling and Mixing over Data Pools > Constrained data mixing Files: section-3-base-kyle.tex
- `yen2025helmet` — *HELMET: How to evaluate long-context models effectively and thoroughly* (2025, cited 3x). Used for: benchmark definition or evaluation methodology; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Evaluation benchmark / methodology, Long-context / document understanding. Sections: Appendix > Base Model Additional Evaluation Details > Base Evaluation suites > Base Long-Context suite; Stage 3: Long-context Extension > Overall results Files: LC-luca-YOUMAYTOUCH.tex, section8-appendix-base.tex
- `young2024yi` — *Yi: Open foundation models by 01. ai* (2024, cited 1x). Used for: external baseline model and/or public recipe reference; reasoning / chain-of-thought / thinking-model related work. Role(s): Open-weight model / baseline, Reasoning / thinking. Sections: Post-Training Additional Data Details > \dolciinstructdpo Details > Model pool for LLM-judged pairs Files: section8-appendix-posttrain.tex
- `yu2025dapo` — *Dapo: An open-source llm reinforcement learning system at scale* (2025, cited 17x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: Post-Training Additional Training Details > RL-Zero Details; \olmothreerlzero; \olmothreerlzero > Key Findings > \olmothreerlzero can strongly improve on reasoning; \olmothreerlzero > Key Findings > \olmothreerlzero mix can benchmark challenges in multi-objective RL; \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Data; \olmothreerlzero > Reinforcement Learning From Base with \dolcirlzero > Prompt and eval template; +3 more Files: section-4-think.tex, section-6-rlzero.tex, section8-appendix-posttrain.tex, tables/posttrain_data/rlvr_data.tex
- `yue2025limit-of-rlvr` — *Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model?* (2025, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Key Findings > DPO and SFT both benefit from RL, but DPO remains a better starting point Files: section-4-think.tex
- `zellers-etal-2019-hellaswag` — *HellaSwag: Can a machine really finish your sentence?* (2019, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Files: tables/base_eval/easy_eval_config.tex, tables/base_eval/eval_config.tex
- `zeng2025acecoder` — *Acecoder: Acing coder rl via automated test-case synthesis* (2025a, cited 4x). Used for: reasoning / chain-of-thought / thinking-model related work. Role(s): Reasoning / thinking. Sections: Post-Training Additional Data Details > Coding Data Synthesis Pipeline; \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, section8-appendix-posttrain.tex, tables/posttrain_data/rlvr_data.tex
- `zeng2025rlve` — *Rlve: Scaling up reinforcement learning for language models with adaptive verifiable environments* (2025b, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work. Role(s): Scaling laws / compute framing, Reasoning / thinking. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Cross-capability thinking traces Files: section-3-base-kyle.tex
- `zha2023tablegpt` — *Tablegpt: Towards unifying tables, natural language and commands into one gpt* (2023, cited 4x). Used for: post-training (SFT/DPO/RL*) method or dataset. Role(s): Post-training / alignment / RL. Sections: \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-4-think.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, tables/posttrain_data/think_dpo_mix.tex
- `zhao2023pytorchfsdpexperiencesscaling` — *Pytorch fsdp: Experiences on scaling fully sharded data parallel, 2023* (2023, cited 1x). Used for: compute/scaling framing (tokens, FLOPs, Pareto); training stack / distributed systems / efficiency tooling. Role(s): Scaling laws / compute framing, Infrastructure / systems. Files: tables/base_training/training_config.tex
- `zhao2024interdoc` — *Analysing the impact of sequence composition on language model pre-training* (2024b, cited 1x). Used for: architecture/optimization component referenced or adapted; long-context training/eval, document understanding, or OCR/PDF pipelines. Role(s): Architecture / optimization component, Long-context / document understanding. Sections: Stage 3: Long-context Extension > Curating a Training Recipe for Extension > Intra-document masking Files: LC-luca-YOUMAYTOUCH.tex
- `zhao2024wildchat` — *Wildchat: 1m chatgpt interaction logs in the wild* (2024a, cited 7x). Used for: dataset, data-mix ingredient, or data-processing/filtering method; compute/scaling framing (tokens, FLOPs, Pareto); reasoning / chain-of-thought / thinking-model related work; tool-use or function-calling interface/eval context; post-training (SFT/DPO/RL*) method or dataset. Role(s): Data / preprocessing / filtering, Scaling laws / compute framing, Reasoning / thinking, Tool use / function calling, Post-training / alignment / RL. Sections: Appendix > Base Model Additional Evaluation Details > New Evaluation Benchmarks > Masked perplexity; \olmothreebase > Stage 1: Pretraining > Preparing our Web Data Pool > Topic and quality classification; \olmothreeinstruct > Supervised Finetuning with \dolciinstructsft > Curating \dolciinstructsft > Step 1. Sourcing Prompts and Completions; \olmothreethinking > Supervised Finetuning with \dolcithinksft > \dolcithinksft: Data Curation > Step 1: sourcing prompts and generating reasoning traces Files: section-3-base-kyle.tex, section-4-think.tex, section-5-instruct-pradeep.tex, section8-appendix-base.tex, tables/posttrain_data/instruct_prompts.tex, tables/posttrain_data/prompt_table.tex, +1 more
- `zheng2023judging` — *Judging llm-as-a-judge with mt-bench and chatbot arena* (2023, cited 2x). Used for: benchmark definition or evaluation methodology. Role(s): Evaluation benchmark / methodology. Sections: Post-Training Additional Evaluation Details > General Evaluation Settings > Is AlpacaEval useful? Files: section8-appendix-posttrain.tex
- `zhong2023agieval` — *Agieval: A human-centric benchmark for evaluating foundation models* (2023, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Files: tables/posttrain/eval_config_posttrain.tex
- `zhou2023instructionfollowingevaluationlargelanguage` — *Instruction-following evaluation for large language models, 2023* (2023, cited 2x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work; post-training (SFT/DPO/RL*) method or dataset. Role(s): Evaluation benchmark / methodology, Reasoning / thinking, Post-training / alignment / RL. Sections: \olmothreethinking > Reinforcement Learning with \olmothreerl: The Cherry on Top > \textsc{Dolci-Think-RL > Step 1: sourcing prompts Files: section-4-think.tex, tables/posttrain/eval_config_posttrain.tex
- `zhou2025megamath` — *Megamath: Pushing the limits of open math corpora* (2025, cited 1x). Used for: benchmark definition or evaluation methodology; reasoning / chain-of-thought / thinking-model related work. Role(s): Evaluation benchmark / methodology, Reasoning / thinking. Sections: \olmothreebase > Stage 2: Midtraining > Capability Improvements for Final Data Mix > Math capabilities Files: section-3-base-kyle.tex
- `zhuo2024bigcodebench` — *Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions* (2024, cited 1x). Used for: benchmark definition or evaluation methodology; tool-use or function-calling interface/eval context. Role(s): Evaluation benchmark / methodology, Tool use / function calling. Files: tables/base_eval/eval_config.tex

